{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 42)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m42\u001b[0m\n\u001b[0;31m    with tf.Graph().as_default():\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "   This program is for SegNet.\n",
    "'''\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.framework import dtypes\n",
    "\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import math\n",
    "from datetime import datetime\n",
    "import time\n",
    "from PIL import Image\n",
    "from math import ceil\n",
    "from tensorflow.python.ops import gen_nn_ops\n",
    "# modules\n",
    "#from Utils import _variable_with_weight_decay, _variable_on_cpu, _add_loss_summaries, _activation_summary, print_hist_summery, get_hist, per_class_acc, writeImage\n",
    "#from Inputs import *\n",
    "\n",
    "'''-------'''\n",
    "# parma presetting\n",
    "IMAGE_HEIGHT = 360\n",
    "IMAGE_WIDTH = 480\n",
    "IMAGE_DEPTH = 3\n",
    "\n",
    "'''------------------------------------------------------------------'''\n",
    "##input\n",
    "\n",
    "def get_filename_list(filename):\n",
    "\t# 拿到数据集\n",
    "\tfd =open(filename)\n",
    "\tfor line in fd:\n",
    "\t\tline=line.strip().split(\" \")\n",
    "\t\timage_path=line[0]\n",
    "\t\tlabel_path=line[1]\n",
    "\t\n",
    "\treturn image_path,label_path\n",
    "\n",
    "def CamVidInput(inputdatafilename,inputlabelfilename,batch_size):\n",
    "    \"\"\"\n",
    "    inputdatafilename: 输入data\n",
    "    inputlabelfilename: 输入y\n",
    "    batch_size: 一次计算的量\n",
    "    读到文件名队列中,然后读出图片.reshape\n",
    "    \"\"\"\n",
    "    images=tf.convert_to_tensor(inputdatafilename,dtype=dtypes.string)\n",
    "    labels=tf.convert_to_tensor(inputlabelfilename,dtype=dtypes.string)\n",
    "    \n",
    "    filename_queue=tf.train.slice_input_producer([images,labels],shuffle=True)\n",
    "    image_val=tf.read_file(filename_queue[0])\n",
    "    label_val=tf.read_file(filename_queue[1])\n",
    "    \n",
    "    image_bytes=tf.image.decode_png(image_val)\n",
    "    label_bytes=tf.image.decode_png(label_val)\n",
    "    \n",
    "    # 把读到的png图片做一个reshape\n",
    "    image=tf.reshape(image_bytes,(IMAGE_HEIGHT,IMAGE_WIDTH,IMAGE_DEPTH))\n",
    "    label=tf.reshape(label_bytes,(IMAGE_HEIGHT,IMAGE_WIDTH,1))\n",
    "    \n",
    "    return image,label\n",
    "    \n",
    "\n",
    "\n",
    "'''------------------------------------------------------------------'''\n",
    "\n",
    "def training(trainfilepath,valfilepath,batch_size,image_width,image_height,image_ch,max_steps):\n",
    "\ttrain_image_filenames,train_label_filenames=get_filename_list(trainfilepath)\n",
    "\tval_image_filenames,val_label_filenames=get_filename_list(valfilepath)\n",
    "\t\n",
    "    startstep=0 # 如果是finetune的话不为0.\n",
    "    with tf.Graph().as_default():\n",
    "        # train_data_node和train_label_node\n",
    "        #    这两者作为训练集的data和label.\n",
    "        train_data_node=tf.placeholder(tf.float32,shape=[batch_size,image_height,image_width,image_ch])\n",
    "        train_label_node=tf.placeholder(tf.float32,shape=[batch_size,image_height,image_width,1]) # 它是1个通道.\n",
    "\n",
    "        #phase_train\n",
    "        # phase_train作为conv*的输入.是一个True和false的\n",
    "        phase_train=tf.placeholder(tf.float32,name=\"phase_train\") # 为什么没有设置shape=[]\n",
    "        global_step=tf.variable(0,trainable=False) # 设置步长,不参与训练\n",
    "        \n",
    "        \n",
    "        # 读出camVid\n",
    "        train_images,train_labels=CamVidInput(train_image_filenames,train_label_filenames,batch_size)\n",
    "        val_images,val_labels=CamVidInput(val_image_filenames,val_label_filenames,batch_size)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # 建立encoder+decoder的网络图\n",
    "        #     输入: data和y.\n",
    "        #     返回损失和预测精度\n",
    "        #     phase_train作用,是Bool型\n",
    "        loss,eval_prediction=inference(train_data_node,train_label_node,batch_size,phase_train)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # 建立train的图\n",
    "        train_op=train(loss,global_step)\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            init=tf.global_variables_initializer()\n",
    "            sess.run(init)\n",
    "            \n",
    "            # 创建线程,并用coordinator()管理\n",
    "            coord=tf.train.Coordinator()\n",
    "            threads=tf.train.start_queue_runners(sess=sess,coord=coord)\n",
    "            \n",
    "            \n",
    "            for step in range(startstep,startstep+max_steps):\n",
    "                image_batch,label_batch=sess.run([train_images,train_labels])\n",
    "                feed_dict={\n",
    "                    train_data_node:image_batch,\n",
    "                    train_label_node:label_batch,\n",
    "                    phase_train:True\n",
    "                }\n",
    "                _,loss_value=sess.run([train_op,loss],feed_dict=feed_dict) # 第一个_是不关心的.\n",
    "                if step%10==0:\n",
    "                    print(\"setp:%d,loss=%.2f\" %(step,loss_value))\n",
    "                pred=sess.run(eval_prediction,feed_dict=feed_dict)\n",
    "                print(\"pred:%s\"pred)\n",
    "    \n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
