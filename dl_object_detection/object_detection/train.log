env prepare with %s Windows
[main]: model_config: faster_rcnn {
  num_classes: 21
  image_resizer {
    keep_aspect_ratio_resizer {
      min_dimension: 600
      max_dimension: 1024
    }
  }
  feature_extractor {
    type: "faster_rcnn_inception_resnet_v2"
    first_stage_features_stride: 8
  }
  first_stage_anchor_generator {
    grid_anchor_generator {
      height_stride: 8
      width_stride: 8
      scales: 0.25
      scales: 0.5
      scales: 1.0
      scales: 2.0
      aspect_ratios: 0.5
      aspect_ratios: 1.0
      aspect_ratios: 2.0
    }
  }
  first_stage_atrous_rate: 2
  first_stage_box_predictor_conv_hyperparams {
    op: CONV
    regularizer {
      l2_regularizer {
        weight: 0.0
      }
    }
    initializer {
      truncated_normal_initializer {
        stddev: 0.009999999776482582
      }
    }
  }
  first_stage_nms_score_threshold: 0.0
  first_stage_nms_iou_threshold: 0.699999988079071
  first_stage_max_proposals: 300
  first_stage_localization_loss_weight: 2.0
  first_stage_objectness_loss_weight: 1.0
  initial_crop_size: 17
  maxpool_kernel_size: 1
  maxpool_stride: 1
  second_stage_box_predictor {
    mask_rcnn_box_predictor {
      fc_hyperparams {
        op: FC
        regularizer {
          l2_regularizer {
            weight: 0.0
          }
        }
        initializer {
          variance_scaling_initializer {
            factor: 1.0
            uniform: true
            mode: FAN_AVG
          }
        }
      }
      use_dropout: false
      dropout_keep_probability: 1.0
    }
  }
  second_stage_post_processing {
    batch_non_max_suppression {
      score_threshold: 0.0
      iou_threshold: 0.6000000238418579
      max_detections_per_class: 100
      max_total_detections: 100
    }
    score_converter: SOFTMAX
  }
  second_stage_localization_loss_weight: 2.0
  second_stage_classification_loss_weight: 1.0
}

[main]: train_config: batch_size: 1
data_augmentation_options {
  random_horizontal_flip {
  }
}
optimizer {
  momentum_optimizer {
    learning_rate {
      manual_step_learning_rate {
        initial_learning_rate: 0.0003000000142492354
        schedule {
          step: 0
          learning_rate: 0.0003000000142492354
        }
        schedule {
          step: 900000
          learning_rate: 2.9999999242136255e-05
        }
        schedule {
          step: 1200000
          learning_rate: 3.000000106112566e-06
        }
      }
    }
    momentum_optimizer_value: 0.8999999761581421
  }
  use_moving_average: false
}
gradient_clipping_by_norm: 10.0
fine_tune_checkpoint: "D:\\work\\stuff\\modules\\misc\\sprd_camera\\alg\\july\\tf_base\\dl_object_detection\\object_detection\\voc\\pretrain\\model.ckpt"
from_detection_checkpoint: true
num_steps: 200000

[main]: input_config: label_map_path: "D:\\work\\stuff\\modules\\misc\\sprd_camera\\alg\\july\\tf_base\\dl_object_detection\\object_detection\\voc\\pascal_label_map.pbtxt"
tf_record_input_reader {
  input_path: "D:\\work\\stuff\\modules\\misc\\sprd_camera\\alg\\july\\tf_base\\dl_object_detection\\object_detection\\voc\\pascal_train.record"
}

[main]: model_fn: functools.partial(<function build at 0x0000020B972FDEA0>, model_config=faster_rcnn {
  num_classes: 21
  image_resizer {
    keep_aspect_ratio_resizer {
      min_dimension: 600
      max_dimension: 1024
    }
  }
  feature_extractor {
    type: "faster_rcnn_inception_resnet_v2"
    first_stage_features_stride: 8
  }
  first_stage_anchor_generator {
    grid_anchor_generator {
      height_stride: 8
      width_stride: 8
      scales: 0.25
      scales: 0.5
      scales: 1.0
      scales: 2.0
      aspect_ratios: 0.5
      aspect_ratios: 1.0
      aspect_ratios: 2.0
    }
  }
  first_stage_atrous_rate: 2
  first_stage_box_predictor_conv_hyperparams {
    op: CONV
    regularizer {
      l2_regularizer {
        weight: 0.0
      }
    }
    initializer {
      truncated_normal_initializer {
        stddev: 0.009999999776482582
      }
    }
  }
  first_stage_nms_score_threshold: 0.0
  first_stage_nms_iou_threshold: 0.699999988079071
  first_stage_max_proposals: 300
  first_stage_localization_loss_weight: 2.0
  first_stage_objectness_loss_weight: 1.0
  initial_crop_size: 17
  maxpool_kernel_size: 1
  maxpool_stride: 1
  second_stage_box_predictor {
    mask_rcnn_box_predictor {
      fc_hyperparams {
        op: FC
        regularizer {
          l2_regularizer {
            weight: 0.0
          }
        }
        initializer {
          variance_scaling_initializer {
            factor: 1.0
            uniform: true
            mode: FAN_AVG
          }
        }
      }
      use_dropout: false
      dropout_keep_probability: 1.0
    }
  }
  second_stage_post_processing {
    batch_non_max_suppression {
      score_threshold: 0.0
      iou_threshold: 0.6000000238418579
      max_detections_per_class: 100
      max_total_detections: 100
    }
    score_converter: SOFTMAX
  }
  second_stage_localization_loss_weight: 2.0
  second_stage_classification_loss_weight: 1.0
}
, is_training=True)
[main]: create_input_dict_fn: functools.partial(<function build at 0x0000020B972FDAE8>, label_map_path: "D:\\work\\stuff\\modules\\misc\\sprd_camera\\alg\\july\\tf_base\\dl_object_detection\\object_detection\\voc\\pascal_label_map.pbtxt"
tf_record_input_reader {
  input_path: "D:\\work\\stuff\\modules\\misc\\sprd_camera\\alg\\july\\tf_base\\dl_object_detection\\object_detection\\voc\\pascal_train.record"
}
)
[main]: cluster_data: None
[main]: cluster: None
[main]: task_data: {'index': 0, 'type': 'master'}
[main]: task_info: <class '__main__.TaskSpec'>
[main]: create_input_dict_fn: functools.partial(<function build at 0x0000020B972FDAE8>, label_map_path: "D:\\work\\stuff\\modules\\misc\\sprd_camera\\alg\\july\\tf_base\\dl_object_detection\\object_detection\\voc\\pascal_label_map.pbtxt"
tf_record_input_reader {
  input_path: "D:\\work\\stuff\\modules\\misc\\sprd_camera\\alg\\july\\tf_base\\dl_object_detection\\object_detection\\voc\\pascal_train.record"
}
)
[main]: model_fn: functools.partial(<function build at 0x0000020B972FDEA0>, model_config=faster_rcnn {
  num_classes: 21
  image_resizer {
    keep_aspect_ratio_resizer {
      min_dimension: 600
      max_dimension: 1024
    }
  }
  feature_extractor {
    type: "faster_rcnn_inception_resnet_v2"
    first_stage_features_stride: 8
  }
  first_stage_anchor_generator {
    grid_anchor_generator {
      height_stride: 8
      width_stride: 8
      scales: 0.25
      scales: 0.5
      scales: 1.0
      scales: 2.0
      aspect_ratios: 0.5
      aspect_ratios: 1.0
      aspect_ratios: 2.0
    }
  }
  first_stage_atrous_rate: 2
  first_stage_box_predictor_conv_hyperparams {
    op: CONV
    regularizer {
      l2_regularizer {
        weight: 0.0
      }
    }
    initializer {
      truncated_normal_initializer {
        stddev: 0.009999999776482582
      }
    }
  }
  first_stage_nms_score_threshold: 0.0
  first_stage_nms_iou_threshold: 0.699999988079071
  first_stage_max_proposals: 300
  first_stage_localization_loss_weight: 2.0
  first_stage_objectness_loss_weight: 1.0
  initial_crop_size: 17
  maxpool_kernel_size: 1
  maxpool_stride: 1
  second_stage_box_predictor {
    mask_rcnn_box_predictor {
      fc_hyperparams {
        op: FC
        regularizer {
          l2_regularizer {
            weight: 0.0
          }
        }
        initializer {
          variance_scaling_initializer {
            factor: 1.0
            uniform: true
            mode: FAN_AVG
          }
        }
      }
      use_dropout: false
      dropout_keep_probability: 1.0
    }
  }
  second_stage_post_processing {
    batch_non_max_suppression {
      score_threshold: 0.0
      iou_threshold: 0.6000000238418579
      max_detections_per_class: 100
      max_total_detections: 100
    }
    score_converter: SOFTMAX
  }
  second_stage_localization_loss_weight: 2.0
  second_stage_classification_loss_weight: 1.0
}
, is_training=True)
[main]: train_config: batch_size: 1
data_augmentation_options {
  random_horizontal_flip {
  }
}
optimizer {
  momentum_optimizer {
    learning_rate {
      manual_step_learning_rate {
        initial_learning_rate: 0.0003000000142492354
        schedule {
          step: 0
          learning_rate: 0.0003000000142492354
        }
        schedule {
          step: 900000
          learning_rate: 2.9999999242136255e-05
        }
        schedule {
          step: 1200000
          learning_rate: 3.000000106112566e-06
        }
      }
    }
    momentum_optimizer_value: 0.8999999761581421
  }
  use_moving_average: false
}
gradient_clipping_by_norm: 10.0
fine_tune_checkpoint: "D:\\work\\stuff\\modules\\misc\\sprd_camera\\alg\\july\\tf_base\\dl_object_detection\\object_detection\\voc\\pretrain\\model.ckpt"
from_detection_checkpoint: true
num_steps: 200000

[main]: master: 
[main]: task: 0
[main]: FLAGS.num_clones: 1
[main]: worker_replicas: 1
[main]: FLAGS.clone_on_cpu: False
[main]: ps_tasks: 0
[main]: worker_job_name: lonely_worker
[main]: is_chief: True
[main]: train_dir: D:\work\stuff\modules\misc\sprd_camera\alg\july\tf_base\dl_object_detectionvoc/train_dir/
[anchor_generator_builder.build] grid_anchor_generator_config:  height_stride: 8
width_stride: 8
scales: 0.25
scales: 0.5
scales: 1.0
scales: 2.0
aspect_ratios: 0.5
aspect_ratios: 1.0
aspect_ratios: 2.0

[anchor_generator_builder.build] gird_aspect_ratios:  [0.5, 1.0, 2.0]
[anchor_generator_builder.build] gird_base_anchor_size:  [256, 256]
[anchor_generator_builder.build] gird_anchor_stride:  [8, 8]
[anchor_generator_builder.build] gird_anchor_offset:  [0, 0]
[argmax_matcher.__init__] _force_match_for_each_row: True
[argmax_matcher.__init__] _negatives_lower_than_unmatched: True
[argmax_matcher.__init__] _matched_threshold: 0.7
[argmax_matcher.__init__] _unmatched_threshold: 0.3
[target_assigner.__init__]: similarity_calc <object_detection.core.region_similarity_calculator.IouSimilarity object at 0x0000020B974C2160>
[target_assigner.__init__]: matcher <object_detection.matchers.argmax_matcher.ArgMaxMatcher object at 0x0000020B974C2048>
[target_assigner.__init__]: box_coder <object_detection.box_coders.faster_rcnn_box_coder.FasterRcnnBoxCoder object at 0x0000020B974C24A8>
[target_assigner.__init__]: positive_class_weight 1.0
[target_assigner.__init__]: negative_class_weight 1.0
[target_assigner.__init__]: unmatched_cls_target None
[argmax_matcher.__init__] _force_match_for_each_row: False
[argmax_matcher.__init__] _negatives_lower_than_unmatched: True
[argmax_matcher.__init__] _matched_threshold: 0.5
[argmax_matcher.__init__] _unmatched_threshold: None
[target_assigner.__init__]: similarity_calc <object_detection.core.region_similarity_calculator.IouSimilarity object at 0x0000020B974C2550>
[target_assigner.__init__]: matcher <object_detection.matchers.argmax_matcher.ArgMaxMatcher object at 0x0000020B974C2518>
[target_assigner.__init__]: box_coder <object_detection.box_coders.faster_rcnn_box_coder.FasterRcnnBoxCoder object at 0x0000020B974C26A0>
[target_assigner.__init__]: positive_class_weight 1.0
[target_assigner.__init__]: negative_class_weight 1.0
[target_assigner.__init__]: unmatched_cls_target Tensor("Const_3:0", shape=(22,), dtype=float32)
[balanced_positive_negative_smapler].__init__] _positive_fraction: 0.5
[balanced_positive_negative_smapler].__init__] _positive_fraction: 0.25
[faster_rcnn_meta_arch.__init__] _hard_example_miner: None
[train] tf.device
[train] deploy_config.variables_device() /device:CPU:0
[train] deploy_config.inputs_device() /device:CPU:0
[anchor_generator_builder.build] grid_anchor_generator_config:  height_stride: 8
width_stride: 8
scales: 0.25
scales: 0.5
scales: 1.0
scales: 2.0
aspect_ratios: 0.5
aspect_ratios: 1.0
aspect_ratios: 2.0

[anchor_generator_builder.build] gird_aspect_ratios:  [0.5, 1.0, 2.0]
[anchor_generator_builder.build] gird_base_anchor_size:  [256, 256]
[anchor_generator_builder.build] gird_anchor_stride:  [8, 8]
[anchor_generator_builder.build] gird_anchor_offset:  [0, 0]
[argmax_matcher.__init__] _force_match_for_each_row: True
[argmax_matcher.__init__] _negatives_lower_than_unmatched: True
[argmax_matcher.__init__] _matched_threshold: 0.7
[argmax_matcher.__init__] _unmatched_threshold: 0.3
[target_assigner.__init__]: similarity_calc <object_detection.core.region_similarity_calculator.IouSimilarity object at 0x0000020B975FDB70>
[target_assigner.__init__]: matcher <object_detection.matchers.argmax_matcher.ArgMaxMatcher object at 0x0000020B975FDB38>
[target_assigner.__init__]: box_coder <object_detection.box_coders.faster_rcnn_box_coder.FasterRcnnBoxCoder object at 0x0000020B975FDCC0>
[target_assigner.__init__]: positive_class_weight 1.0
[target_assigner.__init__]: negative_class_weight 1.0
[target_assigner.__init__]: unmatched_cls_target None
[argmax_matcher.__init__] _force_match_for_each_row: False
[argmax_matcher.__init__] _negatives_lower_than_unmatched: True
[argmax_matcher.__init__] _matched_threshold: 0.5
[argmax_matcher.__init__] _unmatched_threshold: None
[target_assigner.__init__]: similarity_calc <object_detection.core.region_similarity_calculator.IouSimilarity object at 0x0000020B975FDD68>
[target_assigner.__init__]: matcher <object_detection.matchers.argmax_matcher.ArgMaxMatcher object at 0x0000020B975FDCF8>
[target_assigner.__init__]: box_coder <object_detection.box_coders.faster_rcnn_box_coder.FasterRcnnBoxCoder object at 0x0000020B975FDEB8>
[target_assigner.__init__]: positive_class_weight 1.0
[target_assigner.__init__]: negative_class_weight 1.0
[target_assigner.__init__]: unmatched_cls_target Tensor("Const_3:0", shape=(22,), dtype=float32, device=/device:GPU:0)
[balanced_positive_negative_smapler].__init__] _positive_fraction: 0.5
[balanced_positive_negative_smapler].__init__] _positive_fraction: 0.25
[faster_rcnn_meta_arch.__init__] _hard_example_miner: None
faster_rcnn_inception_resnetv2 [preprocess]: resized_inputs Tensor("Preprocessor/map/TensorArrayStack/TensorArrayGatherV3:0", shape=(1, ?, ?, 3), dtype=float32)
[faster_rcnn_meta_arch]._extract_rpn_feature_maps: feature_map_shape[1]:Tensor("strided_slice:0", shape=(), dtype=int32, device=/device:GPU:0), feature_map_shape[0]:Tensor("strided_slice_1:0", shape=(), dtype=int32, device=/device:GPU:0) 
[anchor_generator.generate] num_anchors_per_location: [12]
[anchor_generator.generate] feature_map_shape_list: [(<tf.Tensor 'strided_slice_2:0' shape=() dtype=int32>, <tf.Tensor 'strided_slice_3:0' shape=() dtype=int32>)]
[anchor_generator.generate] self.name_scope(): GridAnchorGenerator
[grid_anchor_generator].generate grid_height: Tensor("strided_slice_2:0", shape=(), dtype=int32, device=/device:GPU:0)
[grid_anchor_generator].generate grid_width: Tensor("strided_slice_3:0", shape=(), dtype=int32, device=/device:GPU:0)
[grid_anchor_generator].generate _scales: [0.25, 0.5, 1.0, 2.0]
[grid_anchor_generator].generate _aspect_ratios: [0.5, 1.0, 2.0]
[grid_anchor_generator].generate _base_anchor_size: Tensor("Const:0", shape=(2,), dtype=float32, device=/device:GPU:0)
[grid_anchor_generator].generate _anchor_stride: Tensor("Const_1:0", shape=(2,), dtype=float32, device=/device:GPU:0)
[grid_anchor_generator].generate _anchor_offset: Tensor("Const_2:0", shape=(2,), dtype=float32, device=/device:GPU:0)
[grid_anchor_generator].generate scales_grid: Tensor("GridAnchorGenerator/Reshape:0", shape=(12,), dtype=float32, device=/device:GPU:0)
[grid_anchor_generator].generate aspect_ratios_grid: Tensor("GridAnchorGenerator/Reshape_1:0", shape=(12,), dtype=float32, device=/device:GPU:0)
[faster_rcnn_meta_arch]._extract_rpn_feature_maps: anchors:  <object_detection.core.box_list.BoxList object at 0x0000020BA042FFD0>
[ConvolutionalBoxPredictor._predict] image_features Tensor("Conv/Relu6:0", shape=(1, ?, ?, 512), dtype=float32, device=/device:GPU:0)
[ConvolutionalBoxPredictor._predict] num_predictions_per_location 12
[ConvolutionalBoxPredictor._predict] features_depth:512,depth:0
[ConvolutionalBoxPredictor._predict] num_class_slots 2
[ConvolutionalBoxPredictor._predict] conv2d :BoxEncodingPredictor _kernel_size:1, output :48 