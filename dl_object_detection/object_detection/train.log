[main]: model_config: faster_rcnn {
  num_classes: 21
  image_resizer {
    keep_aspect_ratio_resizer {
      min_dimension: 600
      max_dimension: 1024
    }
  }
  feature_extractor {
    type: "faster_rcnn_inception_resnet_v2"
    first_stage_features_stride: 8
  }
  first_stage_anchor_generator {
    grid_anchor_generator {
      height_stride: 8
      width_stride: 8
      scales: 0.25
      scales: 0.5
      scales: 1.0
      scales: 2.0
      aspect_ratios: 0.5
      aspect_ratios: 1.0
      aspect_ratios: 2.0
    }
  }
  first_stage_atrous_rate: 2
  first_stage_box_predictor_conv_hyperparams {
    op: CONV
    regularizer {
      l2_regularizer {
        weight: 0.0
      }
    }
    initializer {
      truncated_normal_initializer {
        stddev: 0.009999999776482582
      }
    }
  }
  first_stage_nms_score_threshold: 0.0
  first_stage_nms_iou_threshold: 0.699999988079071
  first_stage_max_proposals: 300
  first_stage_localization_loss_weight: 2.0
  first_stage_objectness_loss_weight: 1.0
  initial_crop_size: 17
  maxpool_kernel_size: 1
  maxpool_stride: 1
  second_stage_box_predictor {
    mask_rcnn_box_predictor {
      fc_hyperparams {
        op: FC
        regularizer {
          l2_regularizer {
            weight: 0.0
          }
        }
        initializer {
          variance_scaling_initializer {
            factor: 1.0
            uniform: true
            mode: FAN_AVG
          }
        }
      }
      use_dropout: false
      dropout_keep_probability: 1.0
    }
  }
  second_stage_post_processing {
    batch_non_max_suppression {
      score_threshold: 0.0
      iou_threshold: 0.6000000238418579
      max_detections_per_class: 100
      max_total_detections: 100
    }
    score_converter: SOFTMAX
  }
  second_stage_localization_loss_weight: 2.0
  second_stage_classification_loss_weight: 1.0
}

[main]: train_config: batch_size: 1
data_augmentation_options {
  random_horizontal_flip {
  }
}
optimizer {
  momentum_optimizer {
    learning_rate {
      manual_step_learning_rate {
        initial_learning_rate: 0.0003000000142492354
        schedule {
          step: 0
          learning_rate: 0.0003000000142492354
        }
        schedule {
          step: 900000
          learning_rate: 2.9999999242136255e-05
        }
        schedule {
          step: 1200000
          learning_rate: 3.000000106112566e-06
        }
      }
    }
    momentum_optimizer_value: 0.8999999761581421
  }
  use_moving_average: false
}
gradient_clipping_by_norm: 10.0
fine_tune_checkpoint: "voc/pretrain/model.ckpt"
from_detection_checkpoint: true
num_steps: 200000

[main]: input_config: label_map_path: "voc/pascal_label_map.pbtxt"
tf_record_input_reader {
  input_path: "voc/pascal_train.record"
}

[main]: model_fn: functools.partial(<function build at 0x7f3f3e4fc268>, model_config=faster_rcnn {
  num_classes: 21
  image_resizer {
    keep_aspect_ratio_resizer {
      min_dimension: 600
      max_dimension: 1024
    }
  }
  feature_extractor {
    type: "faster_rcnn_inception_resnet_v2"
    first_stage_features_stride: 8
  }
  first_stage_anchor_generator {
    grid_anchor_generator {
      height_stride: 8
      width_stride: 8
      scales: 0.25
      scales: 0.5
      scales: 1.0
      scales: 2.0
      aspect_ratios: 0.5
      aspect_ratios: 1.0
      aspect_ratios: 2.0
    }
  }
  first_stage_atrous_rate: 2
  first_stage_box_predictor_conv_hyperparams {
    op: CONV
    regularizer {
      l2_regularizer {
        weight: 0.0
      }
    }
    initializer {
      truncated_normal_initializer {
        stddev: 0.009999999776482582
      }
    }
  }
  first_stage_nms_score_threshold: 0.0
  first_stage_nms_iou_threshold: 0.699999988079071
  first_stage_max_proposals: 300
  first_stage_localization_loss_weight: 2.0
  first_stage_objectness_loss_weight: 1.0
  initial_crop_size: 17
  maxpool_kernel_size: 1
  maxpool_stride: 1
  second_stage_box_predictor {
    mask_rcnn_box_predictor {
      fc_hyperparams {
        op: FC
        regularizer {
          l2_regularizer {
            weight: 0.0
          }
        }
        initializer {
          variance_scaling_initializer {
            factor: 1.0
            uniform: true
            mode: FAN_AVG
          }
        }
      }
      use_dropout: false
      dropout_keep_probability: 1.0
    }
  }
  second_stage_post_processing {
    batch_non_max_suppression {
      score_threshold: 0.0
      iou_threshold: 0.6000000238418579
      max_detections_per_class: 100
      max_total_detections: 100
    }
    score_converter: SOFTMAX
  }
  second_stage_localization_loss_weight: 2.0
  second_stage_classification_loss_weight: 1.0
}
, is_training=True)
[main]: create_input_dict_fn: functools.partial(<function build at 0x7f3f3e4f6e18>, label_map_path: "voc/pascal_label_map.pbtxt"
tf_record_input_reader {
  input_path: "voc/pascal_train.record"
}
)
[main]: cluster_data: None
[main]: cluster: None
[main]: task_data: {'type': 'master', 'index': 0}
[main]: task_info: <class '__main__.TaskSpec'>
[main]: create_input_dict_fn: functools.partial(<function build at 0x7f3f3e4f6e18>, label_map_path: "voc/pascal_label_map.pbtxt"
tf_record_input_reader {
  input_path: "voc/pascal_train.record"
}
)
[main]: model_fn: functools.partial(<function build at 0x7f3f3e4fc268>, model_config=faster_rcnn {
  num_classes: 21
  image_resizer {
    keep_aspect_ratio_resizer {
      min_dimension: 600
      max_dimension: 1024
    }
  }
  feature_extractor {
    type: "faster_rcnn_inception_resnet_v2"
    first_stage_features_stride: 8
  }
  first_stage_anchor_generator {
    grid_anchor_generator {
      height_stride: 8
      width_stride: 8
      scales: 0.25
      scales: 0.5
      scales: 1.0
      scales: 2.0
      aspect_ratios: 0.5
      aspect_ratios: 1.0
      aspect_ratios: 2.0
    }
  }
  first_stage_atrous_rate: 2
  first_stage_box_predictor_conv_hyperparams {
    op: CONV
    regularizer {
      l2_regularizer {
        weight: 0.0
      }
    }
    initializer {
      truncated_normal_initializer {
        stddev: 0.009999999776482582
      }
    }
  }
  first_stage_nms_score_threshold: 0.0
  first_stage_nms_iou_threshold: 0.699999988079071
  first_stage_max_proposals: 300
  first_stage_localization_loss_weight: 2.0
  first_stage_objectness_loss_weight: 1.0
  initial_crop_size: 17
  maxpool_kernel_size: 1
  maxpool_stride: 1
  second_stage_box_predictor {
    mask_rcnn_box_predictor {
      fc_hyperparams {
        op: FC
        regularizer {
          l2_regularizer {
            weight: 0.0
          }
        }
        initializer {
          variance_scaling_initializer {
            factor: 1.0
            uniform: true
            mode: FAN_AVG
          }
        }
      }
      use_dropout: false
      dropout_keep_probability: 1.0
    }
  }
  second_stage_post_processing {
    batch_non_max_suppression {
      score_threshold: 0.0
      iou_threshold: 0.6000000238418579
      max_detections_per_class: 100
      max_total_detections: 100
    }
    score_converter: SOFTMAX
  }
  second_stage_localization_loss_weight: 2.0
  second_stage_classification_loss_weight: 1.0
}
, is_training=True)
[main]: train_config: batch_size: 1
data_augmentation_options {
  random_horizontal_flip {
  }
}
optimizer {
  momentum_optimizer {
    learning_rate {
      manual_step_learning_rate {
        initial_learning_rate: 0.0003000000142492354
        schedule {
          step: 0
          learning_rate: 0.0003000000142492354
        }
        schedule {
          step: 900000
          learning_rate: 2.9999999242136255e-05
        }
        schedule {
          step: 1200000
          learning_rate: 3.000000106112566e-06
        }
      }
    }
    momentum_optimizer_value: 0.8999999761581421
  }
  use_moving_average: false
}
gradient_clipping_by_norm: 10.0
fine_tune_checkpoint: "voc/pretrain/model.ckpt"
from_detection_checkpoint: true
num_steps: 200000

[main]: master: 
[main]: task: 0
[main]: FLAGS.num_clones: 1
[main]: worker_replicas: 1
[main]: FLAGS.clone_on_cpu: False
[main]: ps_tasks: 0
[main]: worker_job_name: lonely_worker
[main]: is_chief: True
[main]: train_dir: voc/train_dir/
faster_rcnn_inception_resnetv2 [preprocess]: resized_inputs Tensor("Preprocessor/map/TensorArrayStack/TensorArrayGatherV3:0", shape=(1, ?, ?, 3), dtype=float32)
[ConvolutionalBoxPredictor._predict] image_features Tensor("Conv/Relu6:0", shape=(1, ?, ?, 512), dtype=float32, device=/device:GPU:0)
[ConvolutionalBoxPredictor._predict] num_predictions_per_location 12
[ConvolutionalBoxPredictor._predict] features_depth:512,depth:0
[ConvolutionalBoxPredictor._predict] num_class_slots 2
[ConvolutionalBoxPredictor._predict] conv2d :BoxEncodingPredictor _kernel_size:1, output :48 
[ConvolutionalBoxPredictor._predict] box_encodings  Tensor("FirstStageBoxPredictor/Reshape:0", shape=(1, ?, 1, 4), dtype=float32, device=/device:GPU:0)
[ConvolutionalBoxPredictor._predict] combined_feature_map_shape  [1, <tf.Tensor 'FirstStageBoxPredictor/strided_slice:0' shape=() dtype=int32>, <tf.Tensor 'FirstStageBoxPredictor/strided_slice_1:0' shape=() dtype=int32>, 512]
[FasterRCNNMetaArch.predict] prediction_dict:  {'rpn_box_predictor_features': <tf.Tensor 'Conv/Relu6:0' shape=(1, ?, ?, 512) dtype=float32>, 'rpn_features_to_crop': <tf.Tensor 'FirstStageFeatureExtractor/InceptionResnetV2/InceptionResnetV2/Repeat_1/block17_20/Relu:0' shape=(1, ?, ?, 1088) dtype=float32>, 'image_shape': <tf.Tensor 'Shape_11:0' shape=(4,) dtype=int32>, 'rpn_box_encodings': <tf.Tensor 'map/TensorArrayStack/TensorArrayGatherV3:0' shape=(1, ?, 4) dtype=float32>, 'rpn_objectness_predictions_with_background': <tf.Tensor 'map_1/TensorArrayStack/TensorArrayGatherV3:0' shape=(1, ?, 2) dtype=float32>, 'anchors': <tf.Tensor 'PruneOutsideWindow/Gather/GatherV2:0' shape=(?, 4) dtype=float32>}
[_create_losses]: detection_model: <object_detection.meta_architectures.faster_rcnn_meta_arch.FasterRCNNMetaArch object at 0x7f3f3e205048>
[_create_losses]: images: Tensor("concat_1:0", shape=(1, ?, ?, 3), dtype=float32, device=/device:GPU:0)
[_create_losses]: groundtruth_boxes_list: (<tf.Tensor 'Slice_4:0' shape=(?, 4) dtype=float32>,)
[_create_losses]: groundtruth_classes_list: (<tf.Tensor 'Reshape_9:0' shape=(?, 21) dtype=float32>,)
[_create_losses]: groundtruth_masks_list: (<tf.Tensor 'Slice_9:0' shape=(?, ?, ?) dtype=bool>,)
[_create_losses]: [USING PREDICT] prediction_dict: {'rpn_box_predictor_features': <tf.Tensor 'Conv/Relu6:0' shape=(1, ?, ?, 512) dtype=float32>, 'rpn_features_to_crop': <tf.Tensor 'FirstStageFeatureExtractor/InceptionResnetV2/InceptionResnetV2/Repeat_1/block17_20/Relu:0' shape=(1, ?, ?, 1088) dtype=float32>, 'image_shape': <tf.Tensor 'Shape_11:0' shape=(4,) dtype=int32>, 'rpn_box_encodings': <tf.Tensor 'map/TensorArrayStack/TensorArrayGatherV3:0' shape=(1, ?, 4) dtype=float32>, 'rpn_objectness_predictions_with_background': <tf.Tensor 'map_1/TensorArrayStack/TensorArrayGatherV3:0' shape=(1, ?, 2) dtype=float32>, 'anchors': <tf.Tensor 'PruneOutsideWindow/Gather/GatherV2:0' shape=(?, 4) dtype=float32>, 'refined_box_encodings': <tf.Tensor 'Squeeze_3:0' shape=(64, 21, 4) dtype=float32>, 'class_predictions_with_background': <tf.Tensor 'Squeeze_4:0' shape=(64, 22) dtype=float32>, 'num_proposals': <tf.Tensor 'stack_8:0' shape=(1,) dtype=int32>, 'proposal_boxes': <tf.Tensor 'map_2/TensorArrayStack/TensorArrayGatherV3:0' shape=(1, 64, 4) dtype=float32>}
[_create_losses]: loss_tensor: Tensor("Loss/BoxClassifierLoss/mul_4:0", shape=(), dtype=float32, device=/device:GPU:0)
