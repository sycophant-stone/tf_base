{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## useful model building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-a1846f8bcf29>, line 24)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-a1846f8bcf29>\"\u001b[0;36m, line \u001b[0;32m24\u001b[0m\n\u001b[0;31m    with tf.variable_scope('unit_%d'%(i+1),values=[net])\u001b[0m\n\u001b[0m                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "slim=tf.contrib.slim\n",
    "import collections\n",
    "from tensorflow.contrib.slim.nets import resnet_utils\n",
    "LOGITS_SCOPE_NAME = 'logits'\n",
    "MERGED_LOGITS_SCOPE = 'merged_logits'\n",
    "IMAGE_POOLING_SCOPE = 'image_pooling'\n",
    "ASPP_SCOPE = 'aspp'\n",
    "CONCAT_PROJECTION_SCOPE = 'concat_projection'\n",
    "DECODER_SCOPE = 'decoder'\n",
    "\n",
    "#-----------------------xception65网络----------------------\n",
    "def stack_blocks_dense(net,\n",
    "                       blocks,\n",
    "                       output_stride=None,\n",
    "                       outputs_collections=None):\n",
    "    \"\"\"实现block描述的net\n",
    "    \"\"\"\n",
    "    current_stride=1\n",
    "    rate=1\n",
    "    for block in blocks:\n",
    "        with tf.variable_scope(block.scope,'block',[net]) as sc:\n",
    "            for i,unit in enumerate(block.args):\n",
    "                with tf.variable_scope('unit_%d'%(i+1),values=[net])\n",
    "                if output_stride is not None and current_stride==output_stride:\n",
    "                    net=block.unit_fn(net,rate=rate,**dict(unit,stride=1))\n",
    "                    rate*=unit.get('stride',1)\n",
    "                else:\n",
    "                    net=block.unit_fn(net,rate=1,**unit)\n",
    "                    current_stride=unit.get('stride',1)\n",
    "            net=slim.utils.collect_named_outputs(outputs_collections,sc.name,net)\n",
    "    \n",
    "    return net\n",
    "                    \n",
    "    \n",
    "\n",
    "def xception(inputs,\n",
    "             blocks,\n",
    "             num_classes=None,\n",
    "             is_training=True,\n",
    "             global_pool=True,\n",
    "             keep_prob=0.5,\n",
    "             output_stride=None,\n",
    "             reuse=None,\n",
    "             scope=None):\n",
    "    \"\"\"把Block描述的网络组织起来\n",
    "    args:\n",
    "        blocks: 描述了一系列的xception 网络block.\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(scope,'xception',\n",
    "                          [inputs],reuse=reuse) as sc:\n",
    "        end_points_collection=sc.original_name_scope+'end_points'\n",
    "        with slim.arg_scope([slim.conv2d,\n",
    "                            slim.separable_conv2d,\n",
    "                            xception_module,\n",
    "                            stack_blocks_dense],\n",
    "                           outputs_collections=end_points_collection):\n",
    "            with slim.arg_scope([slim.batch_norm],is_training=is_training):\n",
    "                net=inputs\n",
    "                if output_stride is not None:\n",
    "                    if output_stride%2!=0:\n",
    "                        raise ValueError('output_stride should be a mulitple of 2')\n",
    "                output_stride/=2\n",
    "                # xception的entry flow前面还有两个conv\n",
    "                net=resnet_utils.conv2d_same(net,32,3,stride=2,scope='entry_flow/conv1_1')\n",
    "                net=resnet_utils.conv2d_same(net,64,3,stride=1,scope='entry_flow/conv1_2')\n",
    "                \n",
    "                # 抽取blocks描述的网路\n",
    "                net=stack_blocks_dense(net,blocks,output_stride)\n",
    "                end_points=slim.utils.convert_collection_to_dict(end_points_collection,clear_collection=True)\n",
    "                \n",
    "                if global_pool:\n",
    "                    net=tf.reduce_mean(net,[1,2],name='global_pool',keepdim=True)\n",
    "                    end_points['global_pool']=net\n",
    "                if num_classes:\n",
    "                    net=slim.dropout(net,keep_prob=keep_prob,is_training=is_training,scope='prelogits_dropout')\n",
    "                    net=slim.conv2d(net,num_classes=num_classes,[1,1],activation_fn=None,\n",
    "                                   normalizer_fn=None,scope='logits')\n",
    "                    end_points[sc.name+'/logits']=net\n",
    "                    end_points['predictions']=slim.softmax(net,scope='predictions')\n",
    "                return net,end_points\n",
    "\n",
    "def separable_conv2d_same(inputs,\n",
    "                          num_outputs,\n",
    "                          kernel_size,\n",
    "                          depth_multiplier,\n",
    "                          stride,\n",
    "                          rate=1,\n",
    "                          use_explicit_padding=True,\n",
    "                          regularize_depthwise=False,\n",
    "                          scope=None,\n",
    "                          **kwargs):\n",
    "    \"\"\"3x3的卷积,可分离卷积\n",
    "    \"\"\"\n",
    "    # 两个辅助函数\n",
    "    def _seperable_conv2d(padding):\n",
    "        return slim.separable_conv2d(inputs,\n",
    "                                     num_outputs,\n",
    "                                     kernel_size,\n",
    "                                     depth_muliplier=depth_multiplier,\n",
    "                                     stride=stride,\n",
    "                                     rate=rate,\n",
    "                                     padding=padding,\n",
    "                                     scope=scope,\n",
    "                                     **kwargs)\n",
    "    \n",
    "    def _split_separable_conv2d(padding):\n",
    "        # 这个里边输出节点没有是num_outputs\n",
    "        outputs=slim.separable_conv2d(inputs,\n",
    "                                     None,\n",
    "                                     kernel_size,\n",
    "                                     depth_multiplier=depth_multiplier,\n",
    "                                     stride=stride,\n",
    "                                     rate=rate,\n",
    "                                     padding=padding,\n",
    "                                     scope=scope+'_depthwise',\n",
    "                                     **kwargs)\n",
    "        # 然后加一个1x1的小卷积做的num_outputs.\n",
    "        return slim.conv2d(outputs,\n",
    "                          num_outputs,\n",
    "                          1,\n",
    "                          scope=scope+'_pointwise',\n",
    "                          **kwargs)\n",
    "    is stride ==1 or not use_explicit_padding:\n",
    "        if regularize_depthwise:\n",
    "            # 加正则化,并不是downsampling,\n",
    "            outputs=_seperable_conv2d(padding='SAME')\n",
    "        else:\n",
    "            outputs=_split_separable_conv2d(padding='SAME')\n",
    "    else:\n",
    "        if regularize_depthwise:\n",
    "            outputs=_seperable_conv2d(padding='VALID')\n",
    "        else:\n",
    "            outputs=_split_separable_conv2d(padding='VALID')\n",
    "            \n",
    "    return outputs\n",
    "\n",
    "def xception_module(inputs,\n",
    "                    depth_list,\n",
    "                    skip_connection_type,\n",
    "                    stride,\n",
    "                    unit_rate_list=None,\n",
    "                    rate=1,\n",
    "                    activation_fn_in_separable_conv=False,\n",
    "                    regularize_depthwise=False,\n",
    "                    outputs_collections=None,\n",
    "                    scope=None):\n",
    "    \"\"\" xception模块包括:\n",
    "        'residual'和'shortcut'\n",
    "        residual含有separable conv 3x3\n",
    "        shortcut含有1x1 conv or not\n",
    "        xception不使用max pooling.而是采用separable conv with striding.原因是当前max pooling不支持带洞操作.\n",
    "        skip_connection_type: shortcut和residual的concat方法,conv,sum,none, conv是shortcut通路经过1x1小卷积和residual加和,\n",
    "                              sum是residual和shortcut加和.\n",
    "                              none只采用residual.\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(scope,'xception_module',[inputs]) as sc:\n",
    "        residual=inputs\n",
    "        \n",
    "        # 功能函数,处理relu在sperable conv前还是后.\n",
    "        def _separable_conv(features,depth,kernel_sise,depth_multiplier,\n",
    "                            regularize_depthwise,rate,stride,scope):\n",
    "            if activation_fn_in_separable_conv:\n",
    "                activation_fn=tf.nn.relu\n",
    "            else:\n",
    "                activation_fn=None\n",
    "                features=tf.nn.relu(features)\n",
    "            return separable_conv2d_same(features,\n",
    "                                   depth,\n",
    "                                   kernel_size,\n",
    "                                   depth_multiplier=depth_multiplier,\n",
    "                                   stride=stride,\n",
    "                                   rate=rate,\n",
    "                                   activation_fn=activation_fn,\n",
    "                                   regularize_depthwise=regularize_depthwise,\n",
    "                                   scope=scope)\n",
    "        for i in range(3):\n",
    "            residual=_separable_conv(residual,depth_list[i],\n",
    "                                    kernel_size=3,\n",
    "                                    depth_multiplier=1,\n",
    "                                    regularize_depthwise=regularize_depthwise,\n",
    "                                    rate=rate*unit_rate_list[i],\n",
    "                                    stride=stride if i==2 else 1,\n",
    "                                    scope='separable_conv'+str(i+1))\n",
    "        \n",
    "        if skip_connection_type =='conv':\n",
    "            shortcut=slim.conv2d(inputs,\n",
    "                                depth_list[-1],\n",
    "                                [1,1],\n",
    "                                stride=stride,\n",
    "                                activation_fn=None,\n",
    "                                scope='shortcut')\n",
    "            outputs=residual+shortcut\n",
    "        elif skip_connection_type=='sum':\n",
    "            outputs=residual+shortcut\n",
    "        else: # None, 表示没有shortcut这个捷径\n",
    "            outputs=residual\n",
    "        \n",
    "        return slim.utils.collect_named_outputs(outputs_collections,\n",
    "                                               sc.name,\n",
    "                                               outputs)\n",
    "    \n",
    "\n",
    "class Block(collections.namedtuple('Block', ['scope', 'unit_fn', 'args'])):\n",
    "    \"\"\"xception模块 \n",
    "    unit_fn: xception模块\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "def xception_block(scope,\n",
    "                   depth_list,\n",
    "                   skip_connection_type,\n",
    "                   activation_fn_in_separable_conv,\n",
    "                   regularize_depthwise,\n",
    "                   num_units,\n",
    "                   stride,\n",
    "                   unit_rate_list=None):\n",
    "    \"\"\"构建xception块.\n",
    "    num_units: 描述相同的该块有多少个.\n",
    "    \n",
    "    \"\"\"\n",
    "    return Block(scope, xception_module, [{\n",
    "      'depth_list': depth_list,\n",
    "      'skip_connection_type': skip_connection_type,\n",
    "      'activation_fn_in_separable_conv': activation_fn_in_separable_conv,\n",
    "      'regularize_depthwise': regularize_depthwise,\n",
    "      'stride': stride,\n",
    "      'unit_rate_list': unit_rate_list,\n",
    "  }] * num_units)\n",
    "    \n",
    "def xception_65(inputs,\n",
    "                num_classes=None,\n",
    "                is_training=True,\n",
    "                global_pool=True,\n",
    "                keep_prob=0.5,\n",
    "                output_stride=None,\n",
    "                regularize_depthwise=False,\n",
    "                multi_grid=None,\n",
    "                reuse=None,\n",
    "                scope='xception_65'):\n",
    "    \"\"\"搭建Xception-65 模型\n",
    "    \"\"\"\n",
    "    blocks=[\n",
    "        xception_block('entry_flow/block1',\n",
    "                       depth_list=[128,128,128],\n",
    "                       skip_connection_type='conv',\n",
    "                       activation_fn_in_separable_conv=False,\n",
    "                       regularize_depthwise=,regularize_depthwise,\n",
    "                       num_units=1,\n",
    "                       stride=2),\n",
    "        xception_block('entry_flow/block2',\n",
    "                       depth_list=[256,256,256],\n",
    "                       skip_connection_type='conv',\n",
    "                       activation_fn_in_separable_conv=False,\n",
    "                       regularize_depthwise=regularize_depthwise,\n",
    "                       num_units=1,\n",
    "                       stride=2),\n",
    "        xception_block('entry_flow/block3',\n",
    "                      depth_list=[728,728,728],\n",
    "                      skip_connection_type='conv',\n",
    "                      activation_fn_in_separable_conv=False,\n",
    "                      regularize_depthwise=regularize_depthwise,\n",
    "                      num_units=1,\n",
    "                      stride=2),\n",
    "        \n",
    "        xception_block('middle_flow/block1',\n",
    "                      depth_list=[728,728,728],\n",
    "                      skip_connection_type='sum',\n",
    "                      activation_fn_in_separable_conv=False,\n",
    "                      regularize_depthwise=regularize_depthwise,\n",
    "                      num_units=16,\n",
    "                      stride=1),\n",
    "        \n",
    "        xception_block('exit_flow/block1',\n",
    "                      depth_list=[728,1024,1024],\n",
    "                      skip_connection_type='conv',\n",
    "                      activation_fn_in_separable_conv=False,\n",
    "                      regularize_depthwise=regularize_depthwise,\n",
    "                      num_units=1,\n",
    "                      stride=2),\n",
    "        xception_block('exit_flow/block2',\n",
    "                      depth_list=[1536,1536,2048],\n",
    "                      skip_connection_type='none',\n",
    "                      activation_fn_in_separable_conv=True,\n",
    "                      regularize_depthwise=regularize_depthwise,\n",
    "                      num_units=1,\n",
    "                      stride=1,\n",
    "                      unit_rate_list=multi_grid),\n",
    "        \n",
    "    ]\n",
    "    return xception(inputs,\n",
    "                  blocks=blocks,\n",
    "                  num_classes=num_classes,\n",
    "                  is_training=is_training,\n",
    "                  global_pool=global_pool,\n",
    "                  keep_prob=keep_prob,\n",
    "                  output_stride=output_stride,\n",
    "                  reuse=reuse,\n",
    "                  scope=scope)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#---------------------------------------------\n",
    "\n",
    "def cal_scaled_dim_val(dim,scale_coeff):\n",
    "    \"\"\"利用scale_coeff对dim维做成scale的维度.\n",
    "       这里只是一个计算,计算scale之后的维度数.其实并没有实际scale数据Tensor对象.\n",
    "    \"\"\"\n",
    "    if isinstance(dim,tf.Tensor):\n",
    "        return tf.cast((tf.tofloat(dim)-1.0)*scale_coeff+1.0,tf.int32) # 其实这里边的这个+1.0是为了向上取整\n",
    "    else:\n",
    "        return (float(dim)-1.0)*scale_coeff+1.0\n",
    "\n",
    "\n",
    "def xception_arg_scope(weight_decay=0.00004,\n",
    "                       batch_norm_decay=0.9997,\n",
    "                       batch_norm_epsilon=0.001,\n",
    "                       batch_norm_scale=True,\n",
    "                       weights_initializer_stddev=0.09,\n",
    "                       activation_fn=tf.nn.relu,\n",
    "                       regularize_depthwise=False,\n",
    "                       use_batch_norm=True):\n",
    "    \"\"\"生成xception65 使用的arg_scope.\n",
    "    \n",
    "    \"\"\"\n",
    "    batch_norm_params={\n",
    "      'decay': batch_norm_decay,\n",
    "      'epsilon': batch_norm_epsilon,\n",
    "      'scale': batch_norm_scale,\n",
    "    }\n",
    "    if regularize_depthwise:\n",
    "        depthwise_regularizer=slim.l2_regularizer(weight_decay)\n",
    "    else:\n",
    "        depthwise_regularizer=None\n",
    "    with slim.arg_scope(\n",
    "    [slim.conv2d,slim.separable_conv2d],\n",
    "        weights_initializer=tf.truncated_normal_initializer(stddev=weights_initializer_stddev),\n",
    "        activation_fn=activation_fn,\n",
    "        normalizer_fn=slim.batch_norm if use_batch_norm else None):\n",
    "        with slim.arg_scope([slim.batch_norm],**batch_norm_params):\n",
    "            with slim.arg_scope([slim.conv2d],\n",
    "                               weights_regularizer=slim.l2_regularizer(weight_decay)):\n",
    "                with slim.arg_scope([slim.separable_conv2d],weights_regularizer=depthwise_regularizer) as arg_sc:\n",
    "                    \n",
    "    return arg_sc\n",
    "\n",
    "def _preprocess_zero_mean_unit_range(inputs):\n",
    "    \"\"\"把图像数据转成-1到1\n",
    "    \"\"\"\n",
    "    return tf.to_float(inputs)/255*2.0 -1.0\n",
    "\n",
    "def get_network(network_name, preprocess_images, arg_scope=None):\n",
    "    \"\"\"get network的函数以及对应的参数\n",
    "    \"\"\"\n",
    "    arg_scope=arg_scope or xception_arg_scope() # 在xception默认参数配置基础上\n",
    "    if preprocess_images==True:\n",
    "        #preprocess_function =_preprocess_zero_mean_unit_range\n",
    "    def network_fn(inputs, *args, **kwargs):\n",
    "        with slim.arg_scope(arg_scope):\n",
    "            return xception_65(_preprocess_zero_mean_unit_range(inputs),\n",
    "                              *args,**kwargs)\n",
    "    return network_fn\n",
    "    \n",
    "\n",
    "def local_extract_features(\n",
    "    features,\n",
    "    model_options,\n",
    "    weight_decay=0.0001,\n",
    "    reuse=None,\n",
    "    is_training=False,\n",
    "    fine_tune_batch_norm=False):\n",
    "    \"\"\"对于特定的模型抽取features\n",
    "    \n",
    "    \"\"\"\n",
    "    #做xception的model_variant.\n",
    "    arg_scope=xception_arg_scope(weight_decay=weight_decay,batch_norm_decay=0.9997,\n",
    "                               batch_norm_epsilon=1e-3,\n",
    "                               batch_norm_scale=True,\n",
    "                               regularize_depthwise=False)\n",
    "    temp_network=get_network(\"exception\",preprocess_images=True,arg_scope)\n",
    "    features,endpoints=temp_network(inputs=features,\n",
    "                 num_classes=None,\n",
    "                is_training=is_training,\n",
    "                global_pool=False,\n",
    "                 output_stride=8,\n",
    "                 multi_grid=None,\n",
    "                 reuse=reuse,\n",
    "                 scope='xception_65')\n",
    "    return features,endpoints\n",
    "    \n",
    "    \n",
    "def extract_features(features,\n",
    "                     model_options,\n",
    "                     weight_decay=0.0001,\n",
    "                     reuse=None,\n",
    "                     is_training=False,\n",
    "                     fine_tune_batch_norm=False):\n",
    "    \"\"\"提取特征图和end_point.\n",
    "    \"\"\"\n",
    "    # 提取\n",
    "    features,end_points=local_extract_features(\n",
    "        images,\n",
    "        output_stride=model_options.output_stride,\n",
    "        multi_grid=model_options.multi_grid,\n",
    "        model_variant=model_options.model_variant,\n",
    "        depth_multiplier=model_options.depth_multiplier,\n",
    "        weight_decay=weight_decay,\n",
    "        reuse=reuse,\n",
    "        is_training=in_training,\n",
    "        fine_tune_batch_norm=fine_tune_batch_norm)\n",
    "    \n",
    "    if not model_options.aspp_with_batch_norm:\n",
    "        # aspp不需要batch norm,直接返回features\n",
    "        # 我们知道batch norm是在激活函数之前,对features做的.让其归一化到0~1之间.\n",
    "        return features,end_points\n",
    "    else:\n",
    "        batch_norm_params={\n",
    "            'is_training':is_training and fine_tune_batch_norm,\n",
    "            'decay':0.9997,\n",
    "            'spsilon':1e-5,\n",
    "            'scale':True,\n",
    "        }\n",
    "    # slim.arg_scope对给定的op存储其param\n",
    "    # 构建figure5里边的 Block4之后处理的ASPP部分.\n",
    "    with slim.arg_scope(\n",
    "        [slim.cov2d,slim.separable_conv2d],\n",
    "        weights_regularizer=slim.l2_regularizer(weight_decay),\n",
    "        activation_fn=tf.nn.relu,\n",
    "        normalizer_fn=slim.batch_norm,\n",
    "        padding='SAME',\n",
    "        stride=1,\n",
    "        reuse=reuse):\n",
    "        # 目的是要做batch norm\n",
    "        with slim.arg_scope(\n",
    "            [slim.batch_norm],\n",
    "            **batch_norm_params):\n",
    "            depth=256\n",
    "            branch_logits=[]\n",
    "            # step 1 做一个pooling\n",
    "            # 融合B部分(image pooling).\n",
    "            if model_options.add_image_level_feature:\n",
    "                \n",
    "                if model_options.crop_size is not None:\n",
    "                    image_pooling_crop_size=model_options.image_pooling_crop_size\n",
    "                    if image_pooling_crop_size is None:\n",
    "                        image_pooling_crop_size=model_options.crop_size\n",
    "                    # 计算pooling的scale\n",
    "                    pooling_height=cal_scaled_dim_val(image_pooling_crop_size[0],\n",
    "                                                      1.0/model_options.output_stride)\n",
    "                    pooling_width=cal_scaled_dim_val(image_pooling_crop_size[1],\n",
    "                                                    1.0/model_options.output_stride)\n",
    "                    # 加pooling层\n",
    "                    image_feature_pooled=slim.avg_pool2d(features,\n",
    "                                    [pooling_height,pooling_width],\n",
    "                                    [1,1],\n",
    "                                    padding='VALID')\n",
    "                    # crop size 也需要做一下scale\n",
    "                    resize_height=cal_scaled_dim_val(model_options.crop_size[0],\n",
    "                                                    1.0/model_options.output_stride)\n",
    "                    resize_width=cal_scaled_dim_val(model_ooptions.crop_size[1],\n",
    "                                                   1.0/model_options.output_stride)\n",
    "                else:\n",
    "                    # 没有crop的size,做一个global的pooling\n",
    "                    pooling_height=tf.shape(features)[0]\n",
    "                    pooling_width=tf.shape(features)[1]\n",
    "                    image_feature_pooled=tf.reduce_mean(\n",
    "                        features,\n",
    "                        axis=[1,2])[:,tf.newaxis,tf.newaxis] # 在features基础上再添加两个维度,但是这两个维度还没有其他的填充值.\n",
    "                    resize_height=pooling_height\n",
    "                    resize_width=pooling_width\n",
    "                # 添加一个1x1的卷积\n",
    "                image_feature=slim.conv2d(\n",
    "                    image_feature_pooled,depth,1,scope=IMAGE_POOLING_SCOPE)\n",
    "                # 插值成resize的feature map\n",
    "                image_feature=tf.image.resize_bilinear(image_feature,[resize_height,resize_width],\n",
    "                                                      align_corners=True)\n",
    "                '''\n",
    "                if isinstance(resize_height,tf.Tensor):\n",
    "                    resize_height=None\n",
    "                if isinstance(resize_width,tf.Tensor):\n",
    "                    resize_width=None\n",
    "                '''\n",
    "                image_feature.set_shape([None,resize_height,resize_width,depth])\n",
    "                branch_logits.append(image_feature)\n",
    "            \n",
    "            # step 2 对features做1x1卷积,注意此处并不是对经过pooling的image_feature做1x1卷积.\n",
    "            # 融合A部分(ASPP) 需要1x1\n",
    "            temp=slim.conv2d(features,depth,1,scope=ASPP_SCOPE+str(0))\n",
    "            branch_logits.append(temp)\n",
    "            \n",
    "            # ASPP,的金字塔每层采用不同的atrous rates,此处构建这组atrous pyramid\n",
    "            # 融合A部分(ASPP) 需要3x3 带artous.\n",
    "            if model_option.atrous_rates:\n",
    "                # 3x3卷积\n",
    "                for i,rate in enumerate(model_options.atrous_rates,1):\n",
    "                    scope=ASPP_SCOPE+str(i)\n",
    "                    # 如果采用可分离卷积\n",
    "                    if model_options.aspp_with_separable_conv:\n",
    "                        aspp_features=split_separable_conv2d(\n",
    "                            features,\n",
    "                            filters=depth,\n",
    "                            rate=rate,\n",
    "                            weight_decay=weight_decay,\n",
    "                            scope=scope)\n",
    "                    else:\n",
    "                        aspp_features=slim.conv2d(features,depth,3,rate=rate,scope=scope)\n",
    "                    \n",
    "                    branch_logits.append(aspp_features)\n",
    "             \n",
    "            # 把这些组件组合起来\n",
    "            concat_logits=tf.concat(branch_logits,3)\n",
    "            concat_logits=slim.conv2d(\n",
    "                concat_logits,depth,1,scope=CONCAT_PROJECTION_SCOPE)\n",
    "            concat_logits=slim.dropout(concat_logits,keep_prob=0.9,is_training=is_training,\n",
    "                                      scope=CONCAT_PROJECTION_SCOPE+'_dropout')\n",
    "            \n",
    "                \n",
    "                    \n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "def split_separable_conv2d(inputs,\n",
    "                           filters,\n",
    "                           kernel_size=3,\n",
    "                           rate=1,\n",
    "                           weight_decay=0.00004,\n",
    "                           depthwise_weights_initializer_stddev=0.33,\n",
    "                           pointwise_weights_initializer_stddev=0.06,\n",
    "                           scope=None):\n",
    "    \"\"\"把一个separable covn2d转化成 depthwise 和 pointwise的conv2d\n",
    "        depthwise_filter。一个张量，数据维度是四维[filter_height,filter_width,in_channels,channel_multiplier]，如1中所述，但是卷积深度是1\n",
    "        pointwise_filter 一个张量, 维度是[1, 1, in_ch*ch_muli, out_ch]\n",
    "       注意:\n",
    "            该函数和tf.layers.separable_conv2d是有区别的. 该函数会在depthwise和pointwise间加上一个激活函数\n",
    "    \"\"\"\n",
    "    outputs=slim.separable_conv2d(\n",
    "        inputs,\n",
    "        None,\n",
    "        kernel_size=kernel_size,\n",
    "        depth_multiplier=1, # DM是1\n",
    "        rate=rate,\n",
    "        weights_initializer=tf.truncated_normal_initializer(\n",
    "            stddev=depthwise_weights_initializer_stddev\n",
    "        ),\n",
    "        weight_regularizer=None,\n",
    "        scope=scope+'_depthwise')\n",
    "    return slim.conv2d(\n",
    "        outputs,# 上一层的输出\n",
    "        filters,\n",
    "        1,\n",
    "        weight_initializer=tf.truncated_normal_initializer(\n",
    "            stddev=pointwise_weights_initializer_stddev\n",
    "        ),\n",
    "        weight_regularizer=slim.l2_regularizer(weight_decay),\n",
    "        scope=scope+'_pointwise')\n",
    "    \n",
    "\n",
    "def refine_by_decoder(features,\n",
    "                      end_points,\n",
    "                      decoder_height,\n",
    "                      decoder_width,\n",
    "                      decoder_use_separable_conv=False,\n",
    "                      model_variant=None,\n",
    "                      weight_decay=0.0001,\n",
    "                      reuse=None,\n",
    "                      is_training=False,\n",
    "                      fine_tune_batch_norm=False):\n",
    "    \"\"\" 添加decoder部分\n",
    "    \n",
    "    \"\"\"\n",
    "    batch_norm_params={\n",
    "        'is_training':is_training and fine_tune_batch_norm,\n",
    "        'decay':0.9997,\n",
    "        'epsilon':1e-5,\n",
    "        'scale':True,\n",
    "    }\n",
    "    \n",
    "    with slim.arg_scope(\n",
    "        [slim.conv2d,slim.separable_conv2d],\n",
    "        weight_regularizer=slim.l2_regualarizer(weight_decay),\n",
    "        activation_fn=tf.nn.relu,\n",
    "        normalizer_fn=slim.batch_norm,\n",
    "        padding='SAME',\n",
    "        stride=1,\n",
    "        reuse=reuse):\n",
    "        with slim.arg_scope([slim.batch_norm],**batch_norm_params):\n",
    "            with tf.variable_scope(DECODER_SCOPE,DECODER_SCOPE,[features]):\n",
    "                feature_list=feature_extractor.networks_to_feature_maps[\n",
    "                    model_variant][feature_extractor.DECODER_END_POINTS]\n",
    "                if feature_list is None:\n",
    "                    tf.logging.info('Not found')\n",
    "                    return features\n",
    "                else:\n",
    "                    decoder_features=features\n",
    "                    for i,name in enumerate(feature_list):\n",
    "                        decoder_features_list=[decoder_features]\n",
    "                        if 'mobilenet' in model_variant:\n",
    "                            feature_name=name\n",
    "                        else:\n",
    "                            feature_name='{}/{}'.format(\n",
    "                                feature_extractor.name_scope[model_variant],\n",
    "                                name)\n",
    "                        decoder_features_list.append(\n",
    "                            slim.conv2d(\n",
    "                                end_points[feature_name],\n",
    "                                48,\n",
    "                                1,\n",
    "                                scope='feature_projection'+str(i)))\n",
    "                        \n",
    "                        # resize\n",
    "                        for j,feature in enumerate(decoder_features_list):\n",
    "                            decoder_features_list[j]=tf.image.resize_bilinear(\n",
    "                                feature,[decoder_height,decoder_widht],\n",
    "                                align_corners=True)\n",
    "                            h=(None if isinstance(decoder_height,tf.Tensor)\n",
    "                               else decoder_height)\n",
    "                            w=(None if isinstance(decoder_width,tf.Tensor)\n",
    "                               else decoder_width)\n",
    "                            decoder_features_list[j].set_shape([None,h,w,None])\n",
    "                        decoder_depth=256\n",
    "                        \n",
    "                        if decoder_use_separable_conv:\n",
    "                            decoder_features=split_separable_conv2d(\n",
    "                                tf.concat(decoder_features_list,3),\n",
    "                                filters=decoder_depth,\n",
    "                                rate=1,\n",
    "                                weight_decay=weight_decay,\n",
    "                                scope='decoder_conv0')\n",
    "                            decoder_features=split_separable_conv2d(\n",
    "                                tf.concat(decoder_features_list,3),\n",
    "                                filters=decoder_depth,\n",
    "                                rate=1,\n",
    "                                weight_decay=weight_decay,\n",
    "                                scope='decoder_conv1')\n",
    "                        else:\n",
    "                            num_convs=2\n",
    "                            decoder_features=slim.repeat(\n",
    "                                tf.concat(decoder_features_list,3),\n",
    "                                num_convs,\n",
    "                                slim.conv2d,\n",
    "                                decoder_depth,\n",
    "                                3,\n",
    "                                scope='decoder_conv'+str(i))\n",
    "                            \n",
    "                return decoder_features\n",
    "                            \n",
    "                        \n",
    "                            \n",
    "    \n",
    "                \n",
    "        \n",
    "                    \n",
    "                \n",
    "            \n",
    "        \n",
    "    \n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "def _get_logits(images,model_options,weight_decay=0.0001,reuse=None,is_training=False,\n",
    "               find_tune_batch_norm=False):\n",
    "    \"\"\"生成logits网络.该网络应用到aspp,atrous spatial pyramid pooling.\n",
    "    \"\"\"\n",
    "    # 提取features和end_points.\n",
    "    features,end_points=extract_features(\n",
    "        images,\n",
    "        model_options,\n",
    "        weight_decay=weight_decay,\n",
    "        reuse=reuse,\n",
    "        is_training=is_training,\n",
    "        find_tune_batch_norm=find_tune_batch_norm)\n",
    "    \n",
    "    # 如果decoder 有特殊定义的stride.需要对decoder size做scale\n",
    "    if model_option.decoder_output_stride is not None:\n",
    "        if model_option.crop_size is None:\n",
    "            height=tf.shape(images)[1]\n",
    "            width=tf.shape(images)[2]\n",
    "        else:\n",
    "            # crop存在\n",
    "            height,width=model_option.crop_size\n",
    "        \n",
    "        # 求decoder使用的size.这个是经过decoder_output_stride之后的.\n",
    "        decoder_height=cal_scaled_dim_val(height,1.0/model_options.decoder_output_stride)\n",
    "        decoder_width=cal_scaled_dim_val(wid,1.0/model_options.decoder_output_stride)\n",
    "        \n",
    "        # 对features做重新refine\n",
    "        features=refine_by_decoder(\n",
    "            features,\n",
    "            end_points,\n",
    "            decoder_height=decoder_height,\n",
    "            decoder_widht=decoder_width,\n",
    "            decoder_use_separable_conv=model_options.decoder_use_separable_conv, # 使用离散卷积\n",
    "            model_variant=model_options.model_variant,\n",
    "            weight_decay=weight_decay,\n",
    "            reuse=reuse,\n",
    "            is_training=is_training,\n",
    "            fine_tune_batch_norm=find_tune_batch_norm)\n",
    "\n",
    "    # 获得batch的logits\n",
    "    # batch_normalization作用:\n",
    "    # 在激活函数之前的bn模块,它接受wx+b计算的feature作为输入.可以做到如下几点:\n",
    "    # 1. 提高梯度传播数度,将所有输出归一化到0~1.避免梯度消失.\n",
    "    # 2. 提高模型的收敛速度.(归一化到0~1,所有的feature都是)\n",
    "    # 3. 减少模型对参数初始化的影响.(归一化到0~1)\n",
    "    outputs_to_logits={}\n",
    "    for output in sorted(model_options.outputs_to_num_classes):\n",
    "        outputs_to_logits[output]=get_batch_logits(\n",
    "            features,\n",
    "            model_options.outputs_to_num_classes[output],\n",
    "            model_options.atrous_rates,\n",
    "            aspp_with_batch_norm=model_options.aspp_with_batch_norm, # batch normalization\n",
    "            weight_decay=weight_decay,\n",
    "            reuse=reuse,\n",
    "            scope_suffix=output) # scope_suffix后缀\n",
    "        \n",
    "    return outputs_to_logits\n",
    "        \n",
    "\n",
    "    \n",
    "def multi_scale_logits(images,\n",
    "                       model_options,\n",
    "                       image_pyramid,\n",
    "                       weight_decay=0.0001,\n",
    "                       is_training=False,\n",
    "                       fine_tune_batch_norm=False):\n",
    "    \"\"\"构建logits方法\n",
    "    args:\n",
    "        model_options: 网络配置的定义信息.\n",
    "        image_pyramid: 图像金字塔\n",
    "        weight_decay: 权重衰减\n",
    "    \"\"\"\n",
    "    if not image_pyramid:\n",
    "        image_pyramid=[1.0] # list\n",
    "    # crop size\n",
    "    crop_height=(\n",
    "        model_options.crop_size[0]\n",
    "        if model_options.crop_size else tf.shape(images)[1])\n",
    "    crop_width=(\n",
    "        model_options.crop_size[1]\n",
    "        if model_options.crop_size else tf.shape(images)[0])\n",
    "    # decoder_output_stride 是在decoder单元,提炼分割结果时候使用的 input/output的比\n",
    "    logits_output_stride=(\n",
    "        model_options.decoder_output_stride or model_options.output_stride)\n",
    "    \n",
    "\n",
    "    logit_height=cal_scaled_dim_val(crop_height,max(1.0,max(image_pyramid))/logits_output_stride) # 这个image_pyramid其实不是很清楚它的含义,是同尺寸的images组还是downsize后images\n",
    "    logit_width=cal_scaled_dim_val(crop_width,max(1.0,max(image_pyramid))/logits_output_stride)   # 2018-09-17: 这个image_pyramide是包含了一组图像缩放的fractor.并不是图像本身.\n",
    "    \n",
    "    outputs_to_scales_to_logits={\n",
    "        k:{}\n",
    "        for k in model_options.outputs_to_num_classes\n",
    "    }\n",
    "    \n",
    "    # step 1 对于每一个缩略图\n",
    "    for image_scale in image_pyramid:\n",
    "        if image_scale!=1.0:\n",
    "            # 不是原图,需要缩放\n",
    "            # 有了缩放因子,需要计算对应的缩放尺寸\n",
    "            scaled_height=cal_scaled_dim_val(crop_height,image_scale)\n",
    "            scaled_width=cal_scaled_dim_val(crop_width,image_scale)\n",
    "            scaled_crop_size=[scaled_height,scaled_width]\n",
    "            # 有了缩放尺寸,需要对原图做缩放了\n",
    "            scaled_images=tf.image.resize_bilinear(images,scaled_crop_size,align_corners=True)\n",
    "            \n",
    "            if model_options.crops_size:\n",
    "                scaled_images.set_shape([None,scaled_height,scale_width,3]) # 如果需要crop size的话,我们把scaled_images reshape成3个chn的.\n",
    "        else:\n",
    "            # 原图\n",
    "            scaled_crop_size=model_options.crop_size\n",
    "            scaled_images=images\n",
    "        \n",
    "        # 用做过scale的尺寸替换参数中的crop_size,然后生成网络\n",
    "        updated_options=model_options._replace(crop_size=scaled_crop_size)\n",
    "        outputs_to_logits=_get_logits(\n",
    "            scaled_images,\n",
    "            updated_options,\n",
    "            weight_decay=weight_decay,\n",
    "            reuse=tf.AUTO_REUSE,\n",
    "            is_training=is_training,\n",
    "            fine_tune_batch_norm=fine_tune_batch_norm)\n",
    "        # 此时拿到结果.对结果做一个reshape,以便和其他的scale pyramid做融合使尺寸是合理的.\n",
    "        for output in sorted(outputs_to_logits):\n",
    "            outputs_to_logits[output]=tf.image.resize_bilinear(\n",
    "                outputs_to_logits[output],\n",
    "                [logit_height,logit_width],\n",
    "                align_corners=True)\n",
    "            \n",
    "        # 只有一层pyramid,就可以返回\n",
    "        if len(image_pyramid)==1:\n",
    "            for output in sorted(model_options.outputs_to_num_classes):\n",
    "                # 第k个scaler fractor对应的LOGITS_SCOPE_NAME,AKA,\"logits\"\n",
    "                outputs_to_scales_to_logits[output][LOGITS_SCOPE_NAME]=outputs_to_logits[output]\n",
    "            \n",
    "            return outputs_to_scales_to_logits\n",
    "        \n",
    "        # 如果有多个pyramid fractor,需要按照对应的标签保存 \n",
    "        for output in sorted(model_options.outputs_to_num_classes):\n",
    "            outputs_to_scales_to_logits[output]['logits_%.2f'%image_scale]=outputs_to_logits[output]\n",
    "            \n",
    "    # 把多个pyramid fractor融合\n",
    "    # 需要新创建一个维度,该维度为了融合使用\n",
    "    for output in model_options.outputs_to_num_classes:\n",
    "        all_logits=[\n",
    "            tf.expand_dims(logits,axis=4)\n",
    "            for logits in outputs_to_scales_to_logits[output].values()\n",
    "        ]\n",
    "        # 在这个新维度上做concat( 理解为连接)\n",
    "        all_logits=tf.concat(all_logits,axis=4)\n",
    "        # 根据不同的融合方法采用不同的tf的融合方法\n",
    "        merge_fn=(\n",
    "            tf.reduce_max\n",
    "            if model_options.merge_method=='max' else tf.reduce_mean)\n",
    "        # 在新增维度上融合.\n",
    "        outputs_to_scales_to_logits[output][MERGED_LOGITS_SCOPE]=merge_fn(all_logits,axis=4)\n",
    "    \n",
    "    return outputs_to_scales_to_logits\n",
    "    \n",
    "                \n",
    "    \n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ![image](https://img-blog.csdn.net/20180518234043625?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L29KaU1vRGVZZTEyMzQ1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](http://p0.ifengimg.com/pmop/2018/0326/34D889CEB77343C271F28FE97BBCF0CD5265946B_size25_w1080_h356.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.linspace(1,200,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.        ,   3.01010101,   5.02020202,   7.03030303,\n",
       "         9.04040404,  11.05050505,  13.06060606,  15.07070707,\n",
       "        17.08080808,  19.09090909,  21.1010101 ,  23.11111111,\n",
       "        25.12121212,  27.13131313,  29.14141414,  31.15151515,\n",
       "        33.16161616,  35.17171717,  37.18181818,  39.19191919,\n",
       "        41.2020202 ,  43.21212121,  45.22222222,  47.23232323,\n",
       "        49.24242424,  51.25252525,  53.26262626,  55.27272727,\n",
       "        57.28282828,  59.29292929,  61.3030303 ,  63.31313131,\n",
       "        65.32323232,  67.33333333,  69.34343434,  71.35353535,\n",
       "        73.36363636,  75.37373737,  77.38383838,  79.39393939,\n",
       "        81.4040404 ,  83.41414141,  85.42424242,  87.43434343,\n",
       "        89.44444444,  91.45454545,  93.46464646,  95.47474747,\n",
       "        97.48484848,  99.49494949, 101.50505051, 103.51515152,\n",
       "       105.52525253, 107.53535354, 109.54545455, 111.55555556,\n",
       "       113.56565657, 115.57575758, 117.58585859, 119.5959596 ,\n",
       "       121.60606061, 123.61616162, 125.62626263, 127.63636364,\n",
       "       129.64646465, 131.65656566, 133.66666667, 135.67676768,\n",
       "       137.68686869, 139.6969697 , 141.70707071, 143.71717172,\n",
       "       145.72727273, 147.73737374, 149.74747475, 151.75757576,\n",
       "       153.76767677, 155.77777778, 157.78787879, 159.7979798 ,\n",
       "       161.80808081, 163.81818182, 165.82828283, 167.83838384,\n",
       "       169.84848485, 171.85858586, 173.86868687, 175.87878788,\n",
       "       177.88888889, 179.8989899 , 181.90909091, 183.91919192,\n",
       "       185.92929293, 187.93939394, 189.94949495, 191.95959596,\n",
       "       193.96969697, 195.97979798, 197.98989899, 200.        ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.5\n"
     ]
    }
   ],
   "source": [
    "sess=tf.Session()\n",
    "y=tf.reduce_mean(x)\n",
    "print(sess.run(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 6 7 8]\n",
      "[[[1 2]\n",
      "  [3 4]]\n",
      "\n",
      " [[5 6]\n",
      "  [7 8]]]\n",
      "reduce\n",
      "[2 6]\n",
      "reduce axis=0\n",
      "[[3 4]\n",
      " [5 6]]\n",
      "reduce axis=1\n",
      "[[2 3]\n",
      " [6 7]]\n",
      "reduce axis=2\n",
      "[[1 3]\n",
      " [5 7]]\n"
     ]
    }
   ],
   "source": [
    "#x1=tf.reshape(x,(5,5,5))\n",
    "z= tf.constant([1, 2, 3, 4, 5, 6, 7,8])\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print(sess.run(z))\n",
    "z_r=tf.reshape(z,[2,2,2])\n",
    "print(sess.run(z_r))\n",
    "y_r=tf.reduce_mean(z_r,axis=[1,2])\n",
    "print(\"reduce\")\n",
    "print(sess.run(y_r))\n",
    "y0=tf.reduce_mean(z_r,axis=0)\n",
    "print(\"reduce axis=0\")\n",
    "print(sess.run(y0))\n",
    "\n",
    "y1=tf.reduce_mean(z_r,axis=1)\n",
    "print(\"reduce axis=1\")\n",
    "print(sess.run(y1))\n",
    "\n",
    "\n",
    "y2=tf.reduce_mean(z_r,axis=2)\n",
    "print(\"reduce axis=2\")\n",
    "print(sess.run(y2))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
