{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## useful model building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "slim=tf.contrib.slim\n",
    "\n",
    "LOGITS_SCOPE_NAME = 'logits'\n",
    "MERGED_LOGITS_SCOPE = 'merged_logits'\n",
    "IMAGE_POOLING_SCOPE = 'image_pooling'\n",
    "ASPP_SCOPE = 'aspp'\n",
    "CONCAT_PROJECTION_SCOPE = 'concat_projection'\n",
    "DECODER_SCOPE = 'decoder'\n",
    "def cal_scaled_dim_val(dim,scale_coeff):\n",
    "    \"\"\"利用scale_coeff对dim维做成scale的维度.\n",
    "       这里只是一个计算,计算scale之后的维度数.其实并没有实际scale数据Tensor对象.\n",
    "    \"\"\"\n",
    "    if isinstance(dim,tf.Tensor):\n",
    "        return tf.cast((tf.tofloat(dim)-1.0)*scale_coeff+1.0,tf.int32) # 其实这里边的这个+1.0是为了向上取整\n",
    "    else:\n",
    "        return (float(dim)-1.0)*scale_coeff+1.0\n",
    "\n",
    "def extract_features(features,\n",
    "                     model_options,\n",
    "                     weight_decay=0.0001,\n",
    "                     reuse=None,\n",
    "                     is_training=False,\n",
    "                     fine_tune_batch_norm=False):\n",
    "    \"\"\"提取特征图和end_point.\n",
    "    \"\"\"\n",
    "    # 提取\n",
    "    features,end_points=local_extract_features(\n",
    "        images,\n",
    "        output_stride=model_options.output_stride,\n",
    "        multi_grid=model_options.multi_grid,\n",
    "        model_variant=model_options.model_variant,\n",
    "        depth_multiplier=model_options.depth_multiplier,\n",
    "        weight_decay=weight_decay,\n",
    "        reuse=reuse,\n",
    "        is_training=in_training,\n",
    "        fine_tune_batch_norm=fine_tune_batch_norm)\n",
    "    \n",
    "    if not model_options.aspp_with_batch_norm:\n",
    "        # aspp不需要batch norm,直接返回features\n",
    "        # 我们知道batch norm是在激活函数之前,对features做的.让其归一化到0~1之间.\n",
    "        return features,end_points\n",
    "    else:\n",
    "        batch_norm_params={\n",
    "            'is_training':is_training and fine_tune_batch_norm,\n",
    "            'decay':0.9997,\n",
    "            'spsilon':1e-5,\n",
    "            'scale':True,\n",
    "        }\n",
    "    # slim.arg_scope对给定的op存储其param\n",
    "    # 构建figure5里边的 Block4之后处理的ASPP部分.\n",
    "    with slim.arg_scope(\n",
    "        [slim.cov2d,slim.separable_conv2d],\n",
    "        weights_regularizer=slim.l2_regularizer(weight_decay),\n",
    "        activation_fn=tf.nn.relu,\n",
    "        normalizer_fn=slim.batch_norm,\n",
    "        padding='SAME',\n",
    "        stride=1,\n",
    "        reuse=reuse):\n",
    "        # 目的是要做batch norm\n",
    "        with slim.arg_scope(\n",
    "            [slim.batch_norm],\n",
    "            **batch_norm_params):\n",
    "            depth=256\n",
    "            branch_logits=[]\n",
    "            # step 1 做一个pooling\n",
    "            # 融合B部分(image pooling).\n",
    "            if model_options.add_image_level_feature:\n",
    "                \n",
    "                if model_options.crop_size is not None:\n",
    "                    image_pooling_crop_size=model_options.image_pooling_crop_size\n",
    "                    if image_pooling_crop_size is None:\n",
    "                        image_pooling_crop_size=model_options.crop_size\n",
    "                    # 计算pooling的scale\n",
    "                    pooling_height=cal_scaled_dim_val(image_pooling_crop_size[0],\n",
    "                                                      1.0/model_options.output_stride)\n",
    "                    pooling_width=cal_scaled_dim_val(image_pooling_crop_size[1],\n",
    "                                                    1.0/model_options.output_stride)\n",
    "                    # 加pooling层\n",
    "                    image_feature_pooled=slim.avg_pool2d(features,\n",
    "                                    [pooling_height,pooling_width],\n",
    "                                    [1,1],\n",
    "                                    padding='VALID')\n",
    "                    # crop size 也需要做一下scale\n",
    "                    resize_height=cal_scaled_dim_val(model_options.crop_size[0],\n",
    "                                                    1.0/model_options.output_stride)\n",
    "                    resize_width=cal_scaled_dim_val(model_ooptions.crop_size[1],\n",
    "                                                   1.0/model_options.output_stride)\n",
    "                else:\n",
    "                    # 没有crop的size,做一个global的pooling\n",
    "                    pooling_height=tf.shape(features)[0]\n",
    "                    pooling_width=tf.shape(features)[1]\n",
    "                    image_feature_pooled=tf.reduce_mean(\n",
    "                        features,\n",
    "                        axis=[1,2])[:,tf.newaxis,tf.newaxis] # 在features基础上再添加两个维度,但是这两个维度还没有其他的填充值.\n",
    "                    resize_height=pooling_height\n",
    "                    resize_width=pooling_width\n",
    "                # 添加一个1x1的卷积\n",
    "                image_feature=slim.conv2d(\n",
    "                    image_feature_pooled,depth,1,scope=IMAGE_POOLING_SCOPE)\n",
    "                # 插值成resize的feature map\n",
    "                image_feature=tf.image.resize_bilinear(image_feature,[resize_height,resize_width],\n",
    "                                                      align_corners=True)\n",
    "                '''\n",
    "                if isinstance(resize_height,tf.Tensor):\n",
    "                    resize_height=None\n",
    "                if isinstance(resize_width,tf.Tensor):\n",
    "                    resize_width=None\n",
    "                '''\n",
    "                image_feature.set_shape([None,resize_height,resize_width,depth])\n",
    "                branch_logits.append(image_feature)\n",
    "            \n",
    "            # step 2 对features做1x1卷积,注意此处并不是对经过pooling的image_feature做1x1卷积.\n",
    "            # 融合A部分(ASPP) 需要1x1\n",
    "            temp=slim.conv2d(features,depth,1,scope=ASPP_SCOPE+str(0))\n",
    "            branch_logits.append(temp)\n",
    "            \n",
    "            # ASPP,的金字塔每层采用不同的atrous rates,此处构建这组atrous pyramid\n",
    "            # 融合A部分(ASPP) 需要3x3 带artous.\n",
    "            if model_option.atrous_rates:\n",
    "                # 3x3卷积\n",
    "                for i,rate in enumerate(model_options.atrous_rates,1):\n",
    "                    scope=ASPP_SCOPE+str(i)\n",
    "                    # 如果采用可分离卷积\n",
    "                    if model_options.aspp_with_separable_conv:\n",
    "                        aspp_features=split_separable_conv2d(\n",
    "                            features,\n",
    "                            filters=depth,\n",
    "                            rate=rate,\n",
    "                            weight_decay=weight_decay,\n",
    "                            scope=scope)\n",
    "                    else:\n",
    "                        aspp_features=slim.conv2(features,depth,3,rate=rate,scope=scope)\n",
    "                    \n",
    "                    branch_logits.append(aspp_features)\n",
    "             \n",
    "            # 把这些组件组合起来\n",
    "            concat_logits=tf.concat(branch_logits,3)\n",
    "            concat_logits=slim.conv2d(\n",
    "                concat_logits,depth,1,scope=CONCAT_PROJECTION_SCOPE)\n",
    "            concat_logits=slim.dropout(concat_logits,keep_prob=0.9,is_training=is_training,\n",
    "                                      scope=CONCAT_PROJECTION_SCOPE+'_dropout')\n",
    "            \n",
    "                \n",
    "                    \n",
    "                    \n",
    "                \n",
    "                    \n",
    "                \n",
    "            \n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "def _get_logits(images,model_options,weight_decay=0.0001,reuse=None,is_training=False,\n",
    "               find_tune_batch_norm=False):\n",
    "    \"\"\"生成logits网络.该网络应用到aspp,atrous spatial pyramid pooling.\n",
    "    \"\"\"\n",
    "    # 提取features和end_points.\n",
    "    features,end_points=extract_features(\n",
    "        images,\n",
    "        model_options,\n",
    "        weight_decay=weight_decay,\n",
    "        reuse=reuse,\n",
    "        is_training=is_training,\n",
    "        find_tune_batch_norm=find_tune_batch_norm)\n",
    "    \n",
    "    # 如果decoder 有特殊定义的stride.需要对decoder size做scale\n",
    "    if model_option.decoder_output_stride is not None:\n",
    "        if model_option.crop_size is None:\n",
    "            height=tf.shape(images)[1]\n",
    "            width=tf.shape(images)[2]\n",
    "        else:\n",
    "            # crop存在\n",
    "            height,width=model_option.crop_size\n",
    "        \n",
    "        # 求decoder使用的size.这个是经过decoder_output_stride之后的.\n",
    "        decoder_height=cal_scaled_dim_val(height,1.0/model_options.decoder_output_stride)\n",
    "        decoder_width=cal_scaled_dim_val(wid,1.0/model_options.decoder_output_stride)\n",
    "        \n",
    "        # 对features做重新refine\n",
    "        features=refine_decoder(\n",
    "            features,\n",
    "            end_points,\n",
    "            decoder_height=decoder_height,\n",
    "            decoder_widht=decoder_width,\n",
    "            decoder_use_separable_conv=model_options.decoder_use_separable_conv, # 使用离散卷积\n",
    "            model_variant=model_options.model_variant,\n",
    "            weight_decay=weight_decay,\n",
    "            reuse=reuse,\n",
    "            is_training=is_training,\n",
    "            fine_tune_batch_norm=find_tune_batch_norm)\n",
    "\n",
    "    # 获得batch的logits\n",
    "    # batch_normalization作用:\n",
    "    # 在激活函数之前的bn模块,它接受wx+b计算的feature作为输入.可以做到如下几点:\n",
    "    # 1. 提高梯度传播数度,将所有输出归一化到0~1.避免梯度消失.\n",
    "    # 2. 提高模型的收敛速度.(归一化到0~1,所有的feature都是)\n",
    "    # 3. 减少模型对参数初始化的影响.(归一化到0~1)\n",
    "    outputs_to_logits={}\n",
    "    for output in sorted(model_options.outputs_to_num_classes):\n",
    "        outputs_to_logits[output]=get_batch_logits(\n",
    "            features,\n",
    "            model_options.outputs_to_num_classes[output],\n",
    "            model_options.atrous_rates,\n",
    "            aspp_with_batch_norm=model_options.aspp_with_batch_norm, # batch normalization\n",
    "            weight_decay=weight_decay,\n",
    "            reuse=reuse,\n",
    "            scope_suffix=output) # scope_suffix后缀\n",
    "        \n",
    "    return outputs_to_logits\n",
    "        \n",
    "\n",
    "    \n",
    "def multi_scale_logits(images,\n",
    "                       model_options,\n",
    "                       image_pyramid,\n",
    "                       weight_decay=0.0001,\n",
    "                       is_training=False,\n",
    "                       fine_tune_batch_norm=False):\n",
    "    \"\"\"构建logits方法\n",
    "    args:\n",
    "        model_options: 网络配置的定义信息.\n",
    "        image_pyramid: 图像金字塔\n",
    "        weight_decay: 权重衰减\n",
    "    \"\"\"\n",
    "    if not image_pyramid:\n",
    "        image_pyramid=[1.0] # list\n",
    "    # crop size\n",
    "    crop_height=(\n",
    "        model_options.crop_size[0]\n",
    "        if model_options.crop_size else tf.shape(images)[1])\n",
    "    crop_width=(\n",
    "        model_options.crop_size[1]\n",
    "        if model_options.crop_size else tf.shape(images)[0])\n",
    "    # decoder_output_stride 是在decoder单元,提炼分割结果时候使用的 input/output的比\n",
    "    logits_output_stride=(\n",
    "        model_options.decoder_output_stride or model_options.output_stride)\n",
    "    \n",
    "\n",
    "    logit_height=cal_scaled_dim_val(crop_height,max(1.0,max(image_pyramid))/logits_output_stride) # 这个image_pyramid其实不是很清楚它的含义,是同尺寸的images组还是downsize后images\n",
    "    logit_width=cal_scaled_dim_val(crop_width,max(1.0,max(image_pyramid))/logits_output_stride)   # 2018-09-17: 这个image_pyramide是包含了一组图像缩放的fractor.并不是图像本身.\n",
    "    \n",
    "    outputs_to_scales_to_logits={\n",
    "        k:{}\n",
    "        for k in model_options.outputs_to_num_classes\n",
    "    }\n",
    "    \n",
    "    # step 1 对于每一个缩略图\n",
    "    for image_scale in image_pyramid:\n",
    "        if image_scale!=1.0:\n",
    "            # 不是原图,需要缩放\n",
    "            # 有了缩放因子,需要计算对应的缩放尺寸\n",
    "            scaled_height=cal_scaled_dim_val(crop_height,image_scale)\n",
    "            scaled_width=cal_scaled_dim_val(crop_width,image_scale)\n",
    "            scaled_crop_size=[scaled_height,scaled_width]\n",
    "            # 有了缩放尺寸,需要对原图做缩放了\n",
    "            scaled_images=tf.image.resize_bilinear(images,scaled_crop_size,align_corners=True)\n",
    "            \n",
    "            if model_options.crops_size:\n",
    "                scaled_images.set_shape([None,scaled_height,scale_width,3]) # 如果需要crop size的话,我们把scaled_images reshape成3个chn的.\n",
    "        else:\n",
    "            # 原图\n",
    "            scaled_crop_size=model_options.crop_size\n",
    "            scaled_images=images\n",
    "        \n",
    "        # 用做过scale的尺寸替换参数中的crop_size,然后生成网络\n",
    "        updated_options=model_options._replace(crop_size=scaled_crop_size)\n",
    "        outputs_to_logits=_get_logits(\n",
    "            scaled_images,\n",
    "            updated_options,\n",
    "            weight_decay=weight_decay,\n",
    "            reuse=tf.AUTO_REUSE,\n",
    "            is_training=is_training,\n",
    "            fine_tune_batch_norm=fine_tune_batch_norm)\n",
    "        # 此时拿到结果.对结果做一个reshape,以便和其他的scale pyramid做融合使尺寸是合理的.\n",
    "        for output in sorted(outputs_to_logits):\n",
    "            outputs_to_logits[output]=tf.image.resize_bilinear(\n",
    "                outputs_to_logits[output],\n",
    "                [logit_height,logit_width],\n",
    "                align_corners=True)\n",
    "            \n",
    "        # 只有一层pyramid,就可以返回\n",
    "        if len(image_pyramid)==1:\n",
    "            for output in sorted(model_options.outputs_to_num_classes):\n",
    "                # 第k个scaler fractor对应的LOGITS_SCOPE_NAME,AKA,\"logits\"\n",
    "                outputs_to_scales_to_logits[output][LOGITS_SCOPE_NAME]=outputs_to_logits[output]\n",
    "            \n",
    "            return outputs_to_scales_to_logits\n",
    "        \n",
    "        # 如果有多个pyramid fractor,需要按照对应的标签保存 \n",
    "        for output in sorted(model_options.outputs_to_num_classes):\n",
    "            outputs_to_scales_to_logits[output]['logits_%.2f'%image_scale]=outputs_to_logits[output]\n",
    "            \n",
    "    # 把多个pyramid fractor融合\n",
    "    # 需要新创建一个维度,该维度为了融合使用\n",
    "    for output in model_options.outputs_to_num_classes:\n",
    "        all_logits=[\n",
    "            tf.expand_dims(logits,axis=4)\n",
    "            for logits in outputs_to_scales_to_logits[output].values()\n",
    "        ]\n",
    "        # 在这个新维度上做concat( 理解为连接)\n",
    "        all_logits=tf.concat(all_logits,axis=4)\n",
    "        # 根据不同的融合方法采用不同的tf的融合方法\n",
    "        merge_fn=(\n",
    "            tf.reduce_max\n",
    "            if model_options.merge_method=='max' else tf.reduce_mean)\n",
    "        # 在新增维度上融合.\n",
    "        outputs_to_scales_to_logits[output][MERGED_LOGITS_SCOPE]=merge_fn(all_logits,axis=4)\n",
    "    \n",
    "    return outputs_to_scales_to_logits\n",
    "    \n",
    "                \n",
    "    \n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ![image](https://img-blog.csdn.net/20180518234043625?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L29KaU1vRGVZZTEyMzQ1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](http://p0.ifengimg.com/pmop/2018/0326/34D889CEB77343C271F28FE97BBCF0CD5265946B_size25_w1080_h356.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.linspace(1,200,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.        ,   3.01010101,   5.02020202,   7.03030303,\n",
       "         9.04040404,  11.05050505,  13.06060606,  15.07070707,\n",
       "        17.08080808,  19.09090909,  21.1010101 ,  23.11111111,\n",
       "        25.12121212,  27.13131313,  29.14141414,  31.15151515,\n",
       "        33.16161616,  35.17171717,  37.18181818,  39.19191919,\n",
       "        41.2020202 ,  43.21212121,  45.22222222,  47.23232323,\n",
       "        49.24242424,  51.25252525,  53.26262626,  55.27272727,\n",
       "        57.28282828,  59.29292929,  61.3030303 ,  63.31313131,\n",
       "        65.32323232,  67.33333333,  69.34343434,  71.35353535,\n",
       "        73.36363636,  75.37373737,  77.38383838,  79.39393939,\n",
       "        81.4040404 ,  83.41414141,  85.42424242,  87.43434343,\n",
       "        89.44444444,  91.45454545,  93.46464646,  95.47474747,\n",
       "        97.48484848,  99.49494949, 101.50505051, 103.51515152,\n",
       "       105.52525253, 107.53535354, 109.54545455, 111.55555556,\n",
       "       113.56565657, 115.57575758, 117.58585859, 119.5959596 ,\n",
       "       121.60606061, 123.61616162, 125.62626263, 127.63636364,\n",
       "       129.64646465, 131.65656566, 133.66666667, 135.67676768,\n",
       "       137.68686869, 139.6969697 , 141.70707071, 143.71717172,\n",
       "       145.72727273, 147.73737374, 149.74747475, 151.75757576,\n",
       "       153.76767677, 155.77777778, 157.78787879, 159.7979798 ,\n",
       "       161.80808081, 163.81818182, 165.82828283, 167.83838384,\n",
       "       169.84848485, 171.85858586, 173.86868687, 175.87878788,\n",
       "       177.88888889, 179.8989899 , 181.90909091, 183.91919192,\n",
       "       185.92929293, 187.93939394, 189.94949495, 191.95959596,\n",
       "       193.96969697, 195.97979798, 197.98989899, 200.        ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.5\n"
     ]
    }
   ],
   "source": [
    "sess=tf.Session()\n",
    "y=tf.reduce_mean(x)\n",
    "print(sess.run(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 6 7 8]\n",
      "[[[1 2]\n",
      "  [3 4]]\n",
      "\n",
      " [[5 6]\n",
      "  [7 8]]]\n",
      "reduce\n",
      "[2 6]\n",
      "reduce axis=0\n",
      "[[3 4]\n",
      " [5 6]]\n",
      "reduce axis=1\n",
      "[[2 3]\n",
      " [6 7]]\n",
      "reduce axis=2\n",
      "[[1 3]\n",
      " [5 7]]\n"
     ]
    }
   ],
   "source": [
    "#x1=tf.reshape(x,(5,5,5))\n",
    "z= tf.constant([1, 2, 3, 4, 5, 6, 7,8])\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print(sess.run(z))\n",
    "z_r=tf.reshape(z,[2,2,2])\n",
    "print(sess.run(z_r))\n",
    "y_r=tf.reduce_mean(z_r,axis=[1,2])\n",
    "print(\"reduce\")\n",
    "print(sess.run(y_r))\n",
    "y0=tf.reduce_mean(z_r,axis=0)\n",
    "print(\"reduce axis=0\")\n",
    "print(sess.run(y0))\n",
    "\n",
    "y1=tf.reduce_mean(z_r,axis=1)\n",
    "print(\"reduce axis=1\")\n",
    "print(sess.run(y1))\n",
    "\n",
    "\n",
    "y2=tf.reduce_mean(z_r,axis=2)\n",
    "print(\"reduce axis=2\")\n",
    "print(sess.run(y2))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
