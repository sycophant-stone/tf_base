{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## useful model building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 1208)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m1208\u001b[0m\n\u001b[0;31m    inputs_queue=prefetch_queue.prefetch_queue(\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "slim=tf.contrib.slim\n",
    "prefetch_queue = slim.prefetch_queue\n",
    "import collections\n",
    "from tensorflow.contrib.slim.nets import resnet_utils\n",
    "from deployment import model_deploy\n",
    "LOGITS_SCOPE_NAME = 'logits'\n",
    "MERGED_LOGITS_SCOPE = 'merged_logits'\n",
    "IMAGE_POOLING_SCOPE = 'image_pooling'\n",
    "ASPP_SCOPE = 'aspp'\n",
    "CONCAT_PROJECTION_SCOPE = 'concat_projection'\n",
    "DECODER_SCOPE = 'decoder'\n",
    "\n",
    "#-----------------------xception65网络----------------------\n",
    "def stack_blocks_dense(net,\n",
    "                       blocks,\n",
    "                       output_stride=None,\n",
    "                       outputs_collections=None):\n",
    "    \"\"\"实现block描述的net\n",
    "       其中unit_fn是xception_module函数\n",
    "    \"\"\"\n",
    "    current_stride=1\n",
    "    rate=1\n",
    "    for block in blocks:\n",
    "        with tf.variable_scope(block.scope,'block',[net]) as sc:\n",
    "            for i,unit in enumerate(block.args):\n",
    "                with tf.variable_scope('unit_%d'%(i+1),values=[net]):\n",
    "                    if output_stride is not None and current_stride==output_stride:\n",
    "                        net=block.unit_fn(net,rate=rate,**dict(unit,stride=1))\n",
    "                        rate*=unit.get('stride',1)\n",
    "                    else:\n",
    "                        net=block.unit_fn(net,rate=1,**unit)\n",
    "                        current_stride=unit.get('stride',1)\n",
    "                    net=slim.utils.collect_named_outputs(outputs_collections,sc.name,net)\n",
    "    \n",
    "    return net\n",
    "                    \n",
    "    \n",
    "\n",
    "def xception(inputs,\n",
    "             blocks,\n",
    "             num_classes=None,\n",
    "             is_training=True,\n",
    "             global_pool=True,\n",
    "             keep_prob=0.5,\n",
    "             output_stride=None,\n",
    "             reuse=None,\n",
    "             scope=None):\n",
    "    \"\"\"把Block描述的网络组织起来\n",
    "    args:\n",
    "        blocks: 描述了一系列的xception 网络block.\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(scope,'xception',\n",
    "                          [inputs],reuse=reuse) as sc:\n",
    "        end_points_collection=sc.original_name_scope+'end_points'\n",
    "        with slim.arg_scope([slim.conv2d,\n",
    "                            slim.separable_conv2d,\n",
    "                            xception_module,\n",
    "                            stack_blocks_dense],\n",
    "                           outputs_collections=end_points_collection):\n",
    "            with slim.arg_scope([slim.batch_norm],is_training=is_training):\n",
    "                net=inputs\n",
    "                if output_stride is not None:\n",
    "                    if output_stride%2!=0:\n",
    "                        raise ValueError('output_stride should be a mulitple of 2')\n",
    "                output_stride/=2\n",
    "                # xception的entry flow前面还有两个conv\n",
    "                net=resnet_utils.conv2d_same(net,32,3,stride=2,scope='entry_flow/conv1_1')\n",
    "                net=resnet_utils.conv2d_same(net,64,3,stride=1,scope='entry_flow/conv1_2')\n",
    "                \n",
    "                # 抽取blocks描述的网路\n",
    "                net=stack_blocks_dense(net,blocks,output_stride)\n",
    "                end_points=slim.utils.convert_collection_to_dict(end_points_collection,clear_collection=True)\n",
    "                \n",
    "                if global_pool:\n",
    "                    net=tf.reduce_mean(net,[1,2],name='global_pool',keepdim=True)\n",
    "                    end_points['global_pool']=net\n",
    "                if num_classes:\n",
    "                    net=slim.dropout(net,keep_prob=keep_prob,is_training=is_training,scope='prelogits_dropout')\n",
    "                    net=slim.conv2d(net,num_classes=num_classes,[1,1],activation_fn=None,\n",
    "                                   normalizer_fn=None,scope='logits')\n",
    "                    end_points[sc.name+'/logits']=net\n",
    "                    end_points['predictions']=slim.softmax(net,scope='predictions')\n",
    "                return net,end_points\n",
    "\n",
    "def separable_conv2d_same(inputs,\n",
    "                          num_outputs,\n",
    "                          kernel_size,\n",
    "                          depth_multiplier,\n",
    "                          stride,\n",
    "                          rate=1,\n",
    "                          use_explicit_padding=True,\n",
    "                          regularize_depthwise=False,\n",
    "                          scope=None,\n",
    "                          **kwargs):\n",
    "    \"\"\"3x3的卷积,可分离卷积\n",
    "    \"\"\"\n",
    "    # 两个辅助函数\n",
    "    def _seperable_conv2d(padding):\n",
    "        return slim.separable_conv2d(inputs,\n",
    "                                     num_outputs,\n",
    "                                     kernel_size,\n",
    "                                     depth_muliplier=depth_multiplier,\n",
    "                                     stride=stride,\n",
    "                                     rate=rate,\n",
    "                                     padding=padding,\n",
    "                                     scope=scope,\n",
    "                                     **kwargs)\n",
    "    \n",
    "    def _split_separable_conv2d(padding):\n",
    "        # 这个里边输出节点没有是num_outputs\n",
    "        outputs=slim.separable_conv2d(inputs,\n",
    "                                     None,\n",
    "                                     kernel_size,\n",
    "                                     depth_multiplier=depth_multiplier,\n",
    "                                     stride=stride,\n",
    "                                     rate=rate,\n",
    "                                     padding=padding,\n",
    "                                     scope=scope+'_depthwise',\n",
    "                                     **kwargs)\n",
    "        # 然后加一个1x1的小卷积做的num_outputs.\n",
    "        return slim.conv2d(outputs,\n",
    "                          num_outputs,\n",
    "                          1,\n",
    "                          scope=scope+'_pointwise',\n",
    "                          **kwargs)\n",
    "    is_stride ==1 or not use_explicit_padding:\n",
    "        if regularize_depthwise:\n",
    "            # 加正则化,并不是downsampling,\n",
    "            outputs=_seperable_conv2d(padding='SAME')\n",
    "        else:\n",
    "            outputs=_split_separable_conv2d(padding='SAME')\n",
    "    else:\n",
    "        if regularize_depthwise:\n",
    "            outputs=_seperable_conv2d(padding='VALID')\n",
    "        else:\n",
    "            outputs=_split_separable_conv2d(padding='VALID')\n",
    "            \n",
    "    return outputs\n",
    "\n",
    "def xception_module(inputs,\n",
    "                    depth_list,\n",
    "                    skip_connection_type,\n",
    "                    stride,\n",
    "                    unit_rate_list=None,\n",
    "                    rate=1,\n",
    "                    activation_fn_in_separable_conv=False,\n",
    "                    regularize_depthwise=False,\n",
    "                    outputs_collections=None,\n",
    "                    scope=None):\n",
    "    \"\"\" xception模块包括:\n",
    "        'residual'和'shortcut'\n",
    "        residual含有separable conv 3x3\n",
    "        shortcut含有1x1 conv or not\n",
    "        xception不使用max pooling.而是采用separable conv with striding.原因是当前max pooling不支持带洞操作.\n",
    "        skip_connection_type: shortcut和residual的concat方法,conv,sum,none, conv是shortcut通路经过1x1小卷积和residual加和,\n",
    "                              sum是residual和shortcut加和.\n",
    "                              none只采用residual.\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(scope,'xception_module',[inputs]) as sc:\n",
    "        residual=inputs\n",
    "        \n",
    "        # 功能函数,处理relu在sperable conv前还是后.\n",
    "        def _separable_conv(features,depth,kernel_sise,depth_multiplier,\n",
    "                            regularize_depthwise,rate,stride,scope):\n",
    "            if activation_fn_in_separable_conv:\n",
    "                activation_fn=tf.nn.relu\n",
    "            else:\n",
    "                activation_fn=None\n",
    "                features=tf.nn.relu(features)\n",
    "            return separable_conv2d_same(features,\n",
    "                                   depth,\n",
    "                                   kernel_size,\n",
    "                                   depth_multiplier=depth_multiplier,\n",
    "                                   stride=stride,\n",
    "                                   rate=rate,\n",
    "                                   activation_fn=activation_fn,\n",
    "                                   regularize_depthwise=regularize_depthwise,\n",
    "                                   scope=scope)\n",
    "        for i in range(3):\n",
    "            residual=_separable_conv(residual,depth_list[i],\n",
    "                                    kernel_size=3,\n",
    "                                    depth_multiplier=1,\n",
    "                                    regularize_depthwise=regularize_depthwise,\n",
    "                                    rate=rate*unit_rate_list[i],\n",
    "                                    stride=stride if i==2 else 1,\n",
    "                                    scope='separable_conv'+str(i+1))\n",
    "        \n",
    "        if skip_connection_type =='conv':\n",
    "            shortcut=slim.conv2d(inputs,\n",
    "                                depth_list[-1],\n",
    "                                [1,1],\n",
    "                                stride=stride,\n",
    "                                activation_fn=None,\n",
    "                                scope='shortcut')\n",
    "            outputs=residual+shortcut\n",
    "        elif skip_connection_type=='sum':\n",
    "            outputs=residual+shortcut\n",
    "        else: # None, 表示没有shortcut这个捷径\n",
    "            outputs=residual\n",
    "        \n",
    "        return slim.utils.collect_named_outputs(outputs_collections,\n",
    "                                               sc.name,\n",
    "                                               outputs)\n",
    "    \n",
    "\n",
    "class Block(collections.namedtuple('Block', ['scope', 'unit_fn', 'args'])):\n",
    "    \"\"\"xception模块 \n",
    "    unit_fn: xception模块\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "def xception_block(scope,\n",
    "                   depth_list,\n",
    "                   skip_connection_type,\n",
    "                   activation_fn_in_separable_conv,\n",
    "                   regularize_depthwise,\n",
    "                   num_units,\n",
    "                   stride,\n",
    "                   unit_rate_list=None):\n",
    "    \"\"\"构建xception块.\n",
    "    num_units: 描述相同的该块有多少个.\n",
    "    \n",
    "    \"\"\"\n",
    "    return Block(scope, xception_module, [{\n",
    "      'depth_list': depth_list,\n",
    "      'skip_connection_type': skip_connection_type,\n",
    "      'activation_fn_in_separable_conv': activation_fn_in_separable_conv,\n",
    "      'regularize_depthwise': regularize_depthwise,\n",
    "      'stride': stride,\n",
    "      'unit_rate_list': unit_rate_list,\n",
    "  }] * num_units)\n",
    "    \n",
    "def xception_65(inputs,\n",
    "                num_classes=None,\n",
    "                is_training=True,\n",
    "                global_pool=True,\n",
    "                keep_prob=0.5,\n",
    "                output_stride=None,\n",
    "                regularize_depthwise=False,\n",
    "                multi_grid=None,\n",
    "                reuse=None,\n",
    "                scope='xception_65'):\n",
    "    \"\"\"搭建Xception-65 模型\n",
    "    \"\"\"\n",
    "    blocks=[\n",
    "        xception_block('entry_flow/block1',\n",
    "                       depth_list=[128,128,128],\n",
    "                       skip_connection_type='conv',\n",
    "                       activation_fn_in_separable_conv=False,\n",
    "                       regularize_depthwise=regularize_depthwise,\n",
    "                       num_units=1,\n",
    "                       stride=2),\n",
    "        xception_block('entry_flow/block2',\n",
    "                       depth_list=[256,256,256],\n",
    "                       skip_connection_type='conv',\n",
    "                       activation_fn_in_separable_conv=False,\n",
    "                       regularize_depthwise=regularize_depthwise,\n",
    "                       num_units=1,\n",
    "                       stride=2),\n",
    "        xception_block('entry_flow/block3',\n",
    "                      depth_list=[728,728,728],\n",
    "                      skip_connection_type='conv',\n",
    "                      activation_fn_in_separable_conv=False,\n",
    "                      regularize_depthwise=regularize_depthwise,\n",
    "                      num_units=1,\n",
    "                      stride=2),\n",
    "        \n",
    "        xception_block('middle_flow/block1',\n",
    "                      depth_list=[728,728,728],\n",
    "                      skip_connection_type='sum',\n",
    "                      activation_fn_in_separable_conv=False,\n",
    "                      regularize_depthwise=regularize_depthwise,\n",
    "                      num_units=16,\n",
    "                      stride=1),\n",
    "        \n",
    "        xception_block('exit_flow/block1',\n",
    "                      depth_list=[728,1024,1024],\n",
    "                      skip_connection_type='conv',\n",
    "                      activation_fn_in_separable_conv=False,\n",
    "                      regularize_depthwise=regularize_depthwise,\n",
    "                      num_units=1,\n",
    "                      stride=2),\n",
    "        xception_block('exit_flow/block2',\n",
    "                      depth_list=[1536,1536,2048],\n",
    "                      skip_connection_type='none',\n",
    "                      activation_fn_in_separable_conv=True,\n",
    "                      regularize_depthwise=regularize_depthwise,\n",
    "                      num_units=1,\n",
    "                      stride=1,\n",
    "                      unit_rate_list=multi_grid),\n",
    "        \n",
    "    ]\n",
    "    return xception(inputs,\n",
    "                  blocks=blocks,\n",
    "                  num_classes=num_classes,\n",
    "                  is_training=is_training,\n",
    "                  global_pool=global_pool,\n",
    "                  keep_prob=keep_prob,\n",
    "                  output_stride=output_stride,\n",
    "                  reuse=reuse,\n",
    "                  scope=scope)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#---------------------------------------------\n",
    "\n",
    "def cal_scaled_dim_val(dim,scale_coeff):\n",
    "    \"\"\"利用scale_coeff对dim维做成scale的维度.\n",
    "       这里只是一个计算,计算scale之后的维度数.其实并没有实际scale数据Tensor对象.\n",
    "    \"\"\"\n",
    "    if isinstance(dim,tf.Tensor):\n",
    "        return tf.cast((tf.tofloat(dim)-1.0)*scale_coeff+1.0,tf.int32) # 其实这里边的这个+1.0是为了向上取整\n",
    "    else:\n",
    "        return (float(dim)-1.0)*scale_coeff+1.0\n",
    "\n",
    "\n",
    "def xception_arg_scope(weight_decay=0.00004,\n",
    "                       batch_norm_decay=0.9997,\n",
    "                       batch_norm_epsilon=0.001,\n",
    "                       batch_norm_scale=True,\n",
    "                       weights_initializer_stddev=0.09,\n",
    "                       activation_fn=tf.nn.relu,\n",
    "                       regularize_depthwise=False,\n",
    "                       use_batch_norm=True):\n",
    "    \"\"\"生成xception65 使用的arg_scope.\n",
    "    \n",
    "    \"\"\"\n",
    "    batch_norm_params={\n",
    "      'decay': batch_norm_decay,\n",
    "      'epsilon': batch_norm_epsilon,\n",
    "      'scale': batch_norm_scale,\n",
    "    }\n",
    "    if regularize_depthwise:\n",
    "        depthwise_regularizer=slim.l2_regularizer(weight_decay)\n",
    "    else:\n",
    "        depthwise_regularizer=None\n",
    "    with slim.arg_scope(\n",
    "    [slim.conv2d,slim.separable_conv2d],\n",
    "        weights_initializer=tf.truncated_normal_initializer(stddev=weights_initializer_stddev),\n",
    "        activation_fn=activation_fn,\n",
    "        normalizer_fn=slim.batch_norm if use_batch_norm else None):\n",
    "        with slim.arg_scope([slim.batch_norm],**batch_norm_params):\n",
    "            with slim.arg_scope([slim.conv2d],\n",
    "                               weights_regularizer=slim.l2_regularizer(weight_decay)):\n",
    "                with slim.arg_scope([slim.separable_conv2d],weights_regularizer=depthwise_regularizer) as arg_sc:\n",
    "                    \n",
    "    return arg_sc\n",
    "\n",
    "def _preprocess_zero_mean_unit_range(inputs):\n",
    "    \"\"\"把图像数据转成-1到1\n",
    "    \"\"\"\n",
    "    return tf.to_float(inputs)/255*2.0 -1.0\n",
    "\n",
    "def get_network(network_name, preprocess_images, arg_scope=None):\n",
    "    \"\"\"get network的函数以及对应的参数\n",
    "    \"\"\"\n",
    "    arg_scope=arg_scope or xception_arg_scope() # 在xception默认参数配置基础上\n",
    "    if preprocess_images==True:\n",
    "        #preprocess_function =_preprocess_zero_mean_unit_range\n",
    "    def network_fn(inputs, *args, **kwargs):\n",
    "        with slim.arg_scope(arg_scope):\n",
    "            return xception_65(_preprocess_zero_mean_unit_range(inputs),\n",
    "                              *args,**kwargs)\n",
    "    return network_fn\n",
    "    \n",
    "\n",
    "def local_extract_features(\n",
    "    features,\n",
    "    model_options,\n",
    "    weight_decay=0.0001,\n",
    "    reuse=None,\n",
    "    is_training=False,\n",
    "    fine_tune_batch_norm=False):\n",
    "    \"\"\"对于特定的模型抽取features\n",
    "    \n",
    "    \"\"\"\n",
    "    #做xception的model_variant.\n",
    "    arg_scope=xception_arg_scope(weight_decay=weight_decay,batch_norm_decay=0.9997,\n",
    "                               batch_norm_epsilon=1e-3,\n",
    "                               batch_norm_scale=True,\n",
    "                               regularize_depthwise=False)\n",
    "    temp_network=get_network(\"exception\",preprocess_images=True,arg_scope)\n",
    "    features,endpoints=temp_network(inputs=features,\n",
    "                 num_classes=None,\n",
    "                is_training=is_training,\n",
    "                global_pool=False,\n",
    "                 output_stride=8,\n",
    "                 multi_grid=None,\n",
    "                 reuse=reuse,\n",
    "                 scope='xception_65')\n",
    "    return features,endpoints\n",
    "    \n",
    "    \n",
    "def extract_features(features,\n",
    "                     model_options,\n",
    "                     weight_decay=0.0001,\n",
    "                     reuse=None,\n",
    "                     is_training=False,\n",
    "                     fine_tune_batch_norm=False):\n",
    "    \"\"\"提取特征图和end_point.\n",
    "       返回值:\n",
    "       1. concat_logits, 它是一系列的融合.\n",
    "       首先,主干输出的feature maps.经过image pool产生一个结果; 经过1x1的conv产生一个结果; 经过rates(6,12,18)的aspp产生一组结果.\n",
    "       然后,这些结果会concat成一个输出.\n",
    "       end_points\n",
    "    \"\"\"\n",
    "    # 提取\n",
    "    features,end_points=local_extract_features(\n",
    "        images,\n",
    "        output_stride=model_options.output_stride,\n",
    "        multi_grid=model_options.multi_grid,\n",
    "        model_variant=model_options.model_variant,\n",
    "        depth_multiplier=model_options.depth_multiplier,\n",
    "        weight_decay=weight_decay,\n",
    "        reuse=reuse,\n",
    "        is_training=in_training,\n",
    "        fine_tune_batch_norm=fine_tune_batch_norm)\n",
    "    \n",
    "    if not model_options.aspp_with_batch_norm:\n",
    "        # aspp不需要batch norm,直接返回features\n",
    "        # 我们知道batch norm是在激活函数之前,对features做的.让其归一化到0~1之间.\n",
    "        return features,end_points\n",
    "    else:\n",
    "        batch_norm_params={\n",
    "            'is_training':is_training and fine_tune_batch_norm,\n",
    "            'decay':0.9997,\n",
    "            'spsilon':1e-5,\n",
    "            'scale':True,\n",
    "        }\n",
    "    # slim.arg_scope对给定的op存储其param\n",
    "    # 构建figure5里边的 Block4之后处理的ASPP部分.\n",
    "    with slim.arg_scope(\n",
    "        [slim.cov2d,slim.separable_conv2d],\n",
    "        weights_regularizer=slim.l2_regularizer(weight_decay),\n",
    "        activation_fn=tf.nn.relu,\n",
    "        normalizer_fn=slim.batch_norm,\n",
    "        padding='SAME',\n",
    "        stride=1,\n",
    "        reuse=reuse):\n",
    "        # 目的是要做batch norm\n",
    "        with slim.arg_scope(\n",
    "            [slim.batch_norm],\n",
    "            **batch_norm_params):\n",
    "            depth=256\n",
    "            branch_logits=[]\n",
    "            # step 1 做一个pooling\n",
    "            # 融合B部分(image pooling).\n",
    "            if model_options.add_image_level_feature:\n",
    "                \n",
    "                if model_options.crop_size is not None:\n",
    "                    image_pooling_crop_size=model_options.image_pooling_crop_size\n",
    "                    if image_pooling_crop_size is None:\n",
    "                        image_pooling_crop_size=model_options.crop_size\n",
    "                    # 计算pooling的scale\n",
    "                    pooling_height=cal_scaled_dim_val(image_pooling_crop_size[0],\n",
    "                                                      1.0/model_options.output_stride)\n",
    "                    pooling_width=cal_scaled_dim_val(image_pooling_crop_size[1],\n",
    "                                                    1.0/model_options.output_stride)\n",
    "                    # 加pooling层\n",
    "                    image_feature_pooled=slim.avg_pool2d(features,\n",
    "                                    [pooling_height,pooling_width],# 这个应该是kernel的size\n",
    "                                    [1,1],# 这个应该是hw的strides\n",
    "                                    padding='VALID')\n",
    "                    # crop size 也需要做一下scale\n",
    "                    resize_height=cal_scaled_dim_val(model_options.crop_size[0],\n",
    "                                                    1.0/model_options.output_stride)\n",
    "                    resize_width=cal_scaled_dim_val(model_ooptions.crop_size[1],\n",
    "                                                   1.0/model_options.output_stride)\n",
    "                else:\n",
    "                    # 没有crop的size,做一个global的pooling\n",
    "                    pooling_height=tf.shape(features)[0]\n",
    "                    pooling_width=tf.shape(features)[1]\n",
    "                    image_feature_pooled=tf.reduce_mean(\n",
    "                        features,\n",
    "                        axis=[1,2])[:,tf.newaxis,tf.newaxis] # 在features基础上再添加两个维度,但是这两个维度还没有其他的填充值.\n",
    "                    resize_height=pooling_height\n",
    "                    resize_width=pooling_width\n",
    "                # 添加一个1x1的卷积\n",
    "                image_feature=slim.conv2d(\n",
    "                    image_feature_pooled,depth,1,scope=IMAGE_POOLING_SCOPE)\n",
    "                # 插值成resize的feature map\n",
    "                image_feature=tf.image.resize_bilinear(image_feature,[resize_height,resize_width],\n",
    "                                                      align_corners=True)\n",
    "                '''\n",
    "                if isinstance(resize_height,tf.Tensor):\n",
    "                    resize_height=None\n",
    "                if isinstance(resize_width,tf.Tensor):\n",
    "                    resize_width=None\n",
    "                '''\n",
    "                image_feature.set_shape([None,resize_height,resize_width,depth])\n",
    "                branch_logits.append(image_feature)\n",
    "            \n",
    "            # step 2 对features做1x1卷积,注意此处并不是对经过pooling的image_feature做1x1卷积.\n",
    "            # 融合A部分(ASPP) 需要1x1\n",
    "            temp=slim.conv2d(features,depth,1,scope=ASPP_SCOPE+str(0))\n",
    "            branch_logits.append(temp)\n",
    "            \n",
    "            # ASPP,的金字塔每层采用不同的atrous rates,此处构建这组atrous pyramid\n",
    "            # 融合A部分(ASPP) 需要3x3 带artous.\n",
    "            if model_option.atrous_rates:\n",
    "                # 3x3卷积\n",
    "                for i,rate in enumerate(model_options.atrous_rates,1):\n",
    "                    scope=ASPP_SCOPE+str(i)\n",
    "                    # 如果采用可分离卷积\n",
    "                    if model_options.aspp_with_separable_conv:\n",
    "                        aspp_features=split_separable_conv2d(\n",
    "                            features,\n",
    "                            filters=depth,\n",
    "                            rate=rate,\n",
    "                            weight_decay=weight_decay,\n",
    "                            scope=scope)\n",
    "                    else:\n",
    "                        aspp_features=slim.conv2d(features,depth,3,rate=rate,scope=scope)\n",
    "                    \n",
    "                    branch_logits.append(aspp_features)\n",
    "             \n",
    "            # 把这些组件组合起来\n",
    "            concat_logits=tf.concat(branch_logits,3) # 在通道上增加了.增加了通道\n",
    "            concat_logits=slim.conv2d(\n",
    "                concat_logits,depth,1,scope=CONCAT_PROJECTION_SCOPE)\n",
    "            concat_logits=slim.dropout(concat_logits,keep_prob=0.9,is_training=is_training,\n",
    "                                      scope=CONCAT_PROJECTION_SCOPE+'_dropout')\n",
    "            \n",
    "    return concat_logits,end_points\n",
    "                \n",
    "                    \n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "def split_separable_conv2d(inputs,\n",
    "                           filters,\n",
    "                           kernel_size=3,\n",
    "                           rate=1,\n",
    "                           weight_decay=0.00004,\n",
    "                           depthwise_weights_initializer_stddev=0.33,\n",
    "                           pointwise_weights_initializer_stddev=0.06,\n",
    "                           scope=None):\n",
    "    \"\"\"把一个separable covn2d转化成 depthwise 和 pointwise的conv2d\n",
    "        depthwise_filter。一个张量，数据维度是四维[filter_height,filter_width,in_channels,channel_multiplier]，如1中所述，但是卷积深度是1\n",
    "        pointwise_filter 一个张量, 维度是[1, 1, in_ch*ch_muli, out_ch]\n",
    "       注意:\n",
    "            该函数和tf.layers.separable_conv2d是有区别的. 该函数会在depthwise和pointwise间加上一个激活函数\n",
    "        \n",
    "        filters:\n",
    "            是输出的个数,可理解为num_outputs\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"注意slim.separable_conv2d的outputs参数\n",
    "            如果outputs参数是None,slim.separable_conv2d会跳过point_wise阶段\n",
    "            (num_outputs: The number of pointwise convolution output filters. If is\n",
    "             None, then we skip the pointwise convolution stage.)\n",
    "    \"\"\"\n",
    "    outputs=slim.separable_conv2d(\n",
    "        inputs,\n",
    "        None, # 只做depth_wise阶段,跳过point_wise阶段\n",
    "        kernel_size=kernel_size,\n",
    "        depth_multiplier=1, # DM是1\n",
    "        rate=rate,\n",
    "        weights_initializer=tf.truncated_normal_initializer(\n",
    "            stddev=depthwise_weights_initializer_stddev\n",
    "        ),\n",
    "        weight_regularizer=None,\n",
    "        scope=scope+'_depthwise')\n",
    "    return slim.conv2d(\n",
    "        outputs,# 上一层的输出,接着做1x1xfilters的point wise阶段\n",
    "        filters, # 输出的filter的个数\n",
    "        1,\n",
    "        weight_initializer=tf.truncated_normal_initializer(\n",
    "            stddev=pointwise_weights_initializer_stddev\n",
    "        ),\n",
    "        weight_regularizer=slim.l2_regularizer(weight_decay),\n",
    "        scope=scope+'_pointwise')\n",
    "    \n",
    "\n",
    "def refine_by_decoder(features,\n",
    "                      end_points,\n",
    "                      decoder_height,\n",
    "                      decoder_width,\n",
    "                      decoder_use_separable_conv=False,\n",
    "                      model_variant=None,\n",
    "                      weight_decay=0.0001,\n",
    "                      reuse=None,\n",
    "                      is_training=False,\n",
    "                      fine_tune_batch_norm=False):\n",
    "    \"\"\" 添加decoder部分\n",
    "    \n",
    "    \"\"\"\n",
    "    batch_norm_params={\n",
    "        'is_training':is_training and fine_tune_batch_norm,\n",
    "        'decay':0.9997,\n",
    "        'epsilon':1e-5,\n",
    "        'scale':True,\n",
    "    }\n",
    "    \n",
    "    with slim.arg_scope(\n",
    "        [slim.conv2d,slim.separable_conv2d],\n",
    "        weight_regularizer=slim.l2_regualarizer(weight_decay),\n",
    "        activation_fn=tf.nn.relu,\n",
    "        normalizer_fn=slim.batch_norm,\n",
    "        padding='SAME',\n",
    "        stride=1,\n",
    "        reuse=reuse):\n",
    "        with slim.arg_scope([slim.batch_norm],**batch_norm_params):\n",
    "            with tf.variable_scope(DECODER_SCOPE,DECODER_SCOPE,[features]):\n",
    "                feature_list=feature_extractor.networks_to_feature_maps[\n",
    "                    model_variant][feature_extractor.DECODER_END_POINTS]\n",
    "                if feature_list is None:\n",
    "                    tf.logging.info('Not found')\n",
    "                    return features\n",
    "                else:\n",
    "                    decoder_features=features\n",
    "                    for i,name in enumerate(feature_list):\n",
    "                        decoder_features_list=[decoder_features]\n",
    "                        if 'mobilenet' in model_variant:\n",
    "                            feature_name=name\n",
    "                        else:\n",
    "                            feature_name='{}/{}'.format(\n",
    "                                feature_extractor.name_scope[model_variant],\n",
    "                                name)\n",
    "                        decoder_features_list.append(\n",
    "                            slim.conv2d(\n",
    "                                end_points[feature_name],\n",
    "                                48,\n",
    "                                1,\n",
    "                                scope='feature_projection'+str(i)))\n",
    "                        \n",
    "                        # resize\n",
    "                        for j,feature in enumerate(decoder_features_list):\n",
    "                            decoder_features_list[j]=tf.image.resize_bilinear(\n",
    "                                feature,[decoder_height,decoder_widht],\n",
    "                                align_corners=True)\n",
    "                            h=(None if isinstance(decoder_height,tf.Tensor)\n",
    "                               else decoder_height)\n",
    "                            w=(None if isinstance(decoder_width,tf.Tensor)\n",
    "                               else decoder_width)\n",
    "                            decoder_features_list[j].set_shape([None,h,w,None])\n",
    "                        decoder_depth=256\n",
    "                        \n",
    "                        if decoder_use_separable_conv:\n",
    "                            decoder_features=split_separable_conv2d(\n",
    "                                tf.concat(decoder_features_list,3),\n",
    "                                filters=decoder_depth,\n",
    "                                rate=1,\n",
    "                                weight_decay=weight_decay,\n",
    "                                scope='decoder_conv0')\n",
    "                            decoder_features=split_separable_conv2d(\n",
    "                                tf.concat(decoder_features_list,3),\n",
    "                                filters=decoder_depth,\n",
    "                                rate=1,\n",
    "                                weight_decay=weight_decay,\n",
    "                                scope='decoder_conv1')\n",
    "                        else:\n",
    "                            num_convs=2\n",
    "                            decoder_features=slim.repeat(\n",
    "                                tf.concat(decoder_features_list,3),\n",
    "                                num_convs,\n",
    "                                slim.conv2d,\n",
    "                                decoder_depth,\n",
    "                                3,\n",
    "                                scope='decoder_conv'+str(i))\n",
    "                            \n",
    "                return decoder_features\n",
    "                            \n",
    "                        \n",
    "                            \n",
    "    \n",
    "                \n",
    "        \n",
    "                    \n",
    "                \n",
    "            \n",
    "        \n",
    "    \n",
    "#-------------------------------------------------------------------------------\n",
    "def get_branch_logits(features,\n",
    "                      num_class,\n",
    "                      atrous_rates=None,\n",
    "                      aspp_with_batch_norm=False,\n",
    "                      kernel_size=1,\n",
    "                      weight_decay=0.0001,\n",
    "                      reuse=None,\n",
    "                      scope_suffix=''):\n",
    "    \"\"\" 从模型中获得logits\n",
    "        xception 后接aspp的输出是logits.\n",
    "    \"\"\"\n",
    "    # 当aspp应用bn时,在extract_features之前就用上aspp,这里采用1x1的conv\n",
    "    if aspp_with_batch_norm or atrous_rates is None:\n",
    "        if atrous_rates!=1:\n",
    "            #如果有bn的atrous也有,证明是aspp.需要加一个1x1的conv\n",
    "            raise ValueError('kernel size must be 1')\n",
    "        atrous_rates=[1]\n",
    "    \n",
    "    with slim.arg_scope(# slim.arg_scope作用就是我们可以预先写一些个参数,以后再调用op的时候可以不用写了,减少书写.\n",
    "        [slim.conv2d],\n",
    "        weight_regularizer=slim.l2_regularizer(weight_decay),\n",
    "        weight_initializer=tf.truncated_normal_initializer(stddev=0.01),\n",
    "        reuse=reuse):\n",
    "        with tf.variable_scope(LOGITS_SCOPE_NAME,LOGITS_SCOPE_NAME,[features]):\n",
    "            branch_logits=[] # 对每个atrous算一个分支,对于每个分支都存一个logits.\n",
    "            for i,rate in enumerate(atrous_rates):\n",
    "                scope=scope_suffix\n",
    "                if i:\n",
    "                    scope+='_%d'%i\n",
    "                \n",
    "                branch_logits.append(\n",
    "                    slim.conv2d(\n",
    "                        features,\n",
    "                        num_class,\n",
    "                        kernel_size=kernel_size,\n",
    "                        rate=rate,\n",
    "                        activation_fn=None,\n",
    "                        normalizer_fn=None,\n",
    "                        scope=scope))\n",
    "    \n",
    "    return tf.add_n(branch_logits)\n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "def _get_logits(images,model_options,weight_decay=0.0001,reuse=None,is_training=False,\n",
    "               find_tune_batch_norm=False):\n",
    "    \"\"\"生成logits网络.该网络应用到aspp,atrous spatial pyramid pooling.\n",
    "    \"\"\"\n",
    "    # 提取features和end_points.\n",
    "    features,end_points=extract_features(\n",
    "        images,\n",
    "        model_options,\n",
    "        weight_decay=weight_decay,\n",
    "        reuse=reuse,\n",
    "        is_training=is_training,\n",
    "        find_tune_batch_norm=find_tune_batch_norm)\n",
    "    \n",
    "    # 如果decoder 有特殊定义的stride.需要对decoder size做scale\n",
    "    if model_option.decoder_output_stride is not None:\n",
    "        if model_option.crop_size is None:\n",
    "            height=tf.shape(images)[1]\n",
    "            width=tf.shape(images)[2]\n",
    "        else:\n",
    "            # crop存在\n",
    "            height,width=model_option.crop_size\n",
    "        \n",
    "        # 求decoder使用的size.这个是经过decoder_output_stride之后的.\n",
    "        decoder_height=cal_scaled_dim_val(height,1.0/model_options.decoder_output_stride)\n",
    "        decoder_width=cal_scaled_dim_val(wid,1.0/model_options.decoder_output_stride)\n",
    "        \n",
    "        # 对features做重新refine\n",
    "        # 添加decode部分,之前的deeplab采用了crf,在deeplabV3中没有使用crf.利用sep conv2d替代.\n",
    "        # 只不过这里会使用之前xception的中间产物做融合.\n",
    "        features=refine_by_decoder(\n",
    "            features,\n",
    "            end_points,\n",
    "            decoder_height=decoder_height,\n",
    "            decoder_widht=decoder_width,\n",
    "            decoder_use_separable_conv=model_options.decoder_use_separable_conv, # 使用离散卷积\n",
    "            model_variant=model_options.model_variant,\n",
    "            weight_decay=weight_decay,\n",
    "            reuse=reuse,\n",
    "            is_training=is_training,\n",
    "            fine_tune_batch_norm=find_tune_batch_norm)\n",
    "\n",
    "    # 获得batch的logits\n",
    "    # batch_normalization作用:\n",
    "    # 在激活函数之前的bn模块,它接受wx+b计算的feature作为输入.可以做到如下几点:\n",
    "    # 1. 提高梯度传播数度,将所有输出归一化到0~1.避免梯度消失.\n",
    "    # 2. 提高模型的收敛速度.(归一化到0~1,所有的feature都是)\n",
    "    # 3. 减少模型对参数初始化的影响.(归一化到0~1)\n",
    "    outputs_to_logits={}\n",
    "    for output in sorted(model_options.outputs_to_num_classes):\n",
    "        outputs_to_logits[output]=get_branch_logits(\n",
    "            features,\n",
    "            model_options.outputs_to_num_classes[output],\n",
    "            model_options.atrous_rates,\n",
    "            aspp_with_batch_norm=model_options.aspp_with_batch_norm, # batch normalization\n",
    "            weight_decay=weight_decay,\n",
    "            reuse=reuse,\n",
    "            scope_suffix=output) # scope_suffix后缀\n",
    "        \n",
    "    return outputs_to_logits\n",
    "        \n",
    "\n",
    "    \n",
    "def multi_scale_logits(images,\n",
    "                       model_options,\n",
    "                       image_pyramid,\n",
    "                       weight_decay=0.0001,\n",
    "                       is_training=False,\n",
    "                       fine_tune_batch_norm=False):\n",
    "    \"\"\"构建logits方法\n",
    "    args:\n",
    "        model_options: 网络配置的定义信息.\n",
    "        image_pyramid: 图像金字塔\n",
    "        weight_decay: 权重衰减\n",
    "    \"\"\"\n",
    "    if not image_pyramid:\n",
    "        image_pyramid=[1.0] # list\n",
    "    # crop size\n",
    "    crop_height=(\n",
    "        model_options.crop_size[0]\n",
    "        if model_options.crop_size else tf.shape(images)[1])\n",
    "    crop_width=(\n",
    "        model_options.crop_size[1]\n",
    "        if model_options.crop_size else tf.shape(images)[0])\n",
    "    # decoder_output_stride 是在decoder单元,提炼分割结果时候使用的 input/output的比\n",
    "    logits_output_stride=(\n",
    "        model_options.decoder_output_stride or model_options.output_stride)\n",
    "    \n",
    "\n",
    "    logit_height=cal_scaled_dim_val(crop_height,max(1.0,max(image_pyramid))/logits_output_stride) # 这个image_pyramid其实不是很清楚它的含义,是同尺寸的images组还是downsize后images\n",
    "    logit_width=cal_scaled_dim_val(crop_width,max(1.0,max(image_pyramid))/logits_output_stride)   # 2018-09-17: 这个image_pyramide是包含了一组图像缩放的fractor.并不是图像本身.\n",
    "    \n",
    "    outputs_to_scales_to_logits={\n",
    "        k:{}\n",
    "        for k in model_options.outputs_to_num_classes\n",
    "    }\n",
    "    \n",
    "    # step 1 对于每一个缩略图\n",
    "    for image_scale in image_pyramid:\n",
    "        if image_scale!=1.0:\n",
    "            # 不是原图,需要缩放\n",
    "            # 有了缩放因子,需要计算对应的缩放尺寸\n",
    "            scaled_height=cal_scaled_dim_val(crop_height,image_scale)\n",
    "            scaled_width=cal_scaled_dim_val(crop_width,image_scale)\n",
    "            scaled_crop_size=[scaled_height,scaled_width]\n",
    "            # 有了缩放尺寸,需要对原图做缩放了\n",
    "            scaled_images=tf.image.resize_bilinear(images,scaled_crop_size,align_corners=True)\n",
    "            \n",
    "            if model_options.crops_size:\n",
    "                scaled_images.set_shape([None,scaled_height,scale_width,3]) # 如果需要crop size的话,我们把scaled_images reshape成3个chn的.\n",
    "        else:\n",
    "            # 原图\n",
    "            scaled_crop_size=model_options.crop_size\n",
    "            scaled_images=images\n",
    "        \n",
    "        # 用做过scale的尺寸替换参数中的crop_size,然后生成网络\n",
    "        updated_options=model_options._replace(crop_size=scaled_crop_size)\n",
    "        outputs_to_logits=_get_logits(\n",
    "            scaled_images,\n",
    "            updated_options,\n",
    "            weight_decay=weight_decay,\n",
    "            reuse=tf.AUTO_REUSE,\n",
    "            is_training=is_training,\n",
    "            fine_tune_batch_norm=fine_tune_batch_norm)\n",
    "        # 此时拿到结果.对结果做一个reshape,以便和其他的scale pyramid做融合使尺寸是合理的.\n",
    "        for output in sorted(outputs_to_logits):\n",
    "            outputs_to_logits[output]=tf.image.resize_bilinear(\n",
    "                outputs_to_logits[output],\n",
    "                [logit_height,logit_width],\n",
    "                align_corners=True)\n",
    "            \n",
    "        # 只有一层pyramid,就可以返回\n",
    "        if len(image_pyramid)==1:\n",
    "            for output in sorted(model_options.outputs_to_num_classes):\n",
    "                # 第k个scaler fractor对应的LOGITS_SCOPE_NAME,AKA,\"logits\"\n",
    "                outputs_to_scales_to_logits[output][LOGITS_SCOPE_NAME]=outputs_to_logits[output]\n",
    "            \n",
    "            return outputs_to_scales_to_logits\n",
    "        \n",
    "        # 如果有多个pyramid fractor,需要按照对应的标签保存 \n",
    "        for output in sorted(model_options.outputs_to_num_classes):\n",
    "            outputs_to_scales_to_logits[output]['logits_%.2f'%image_scale]=outputs_to_logits[output]\n",
    "            \n",
    "    # 把多个pyramid fractor融合\n",
    "    # 需要新创建一个维度,该维度为了融合使用\n",
    "    for output in model_options.outputs_to_num_classes:\n",
    "        all_logits=[\n",
    "            tf.expand_dims(logits,axis=4)\n",
    "            for logits in outputs_to_scales_to_logits[output].values()\n",
    "        ]\n",
    "        # 在这个新维度上做concat( 理解为连接)\n",
    "        all_logits=tf.concat(all_logits,axis=4)\n",
    "        # 根据不同的融合方法采用不同的tf的融合方法\n",
    "        merge_fn=(\n",
    "            tf.reduce_max\n",
    "            if model_options.merge_method=='max' else tf.reduce_mean)\n",
    "        # 在新增维度上融合.\n",
    "        outputs_to_scales_to_logits[output][MERGED_LOGITS_SCOPE]=merge_fn(all_logits,axis=4)\n",
    "    \n",
    "    return outputs_to_scales_to_logits\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "# train\n",
    "\n",
    "\n",
    "num_clones=1# 'Number of clones to deploy.')\n",
    "\n",
    "\n",
    "clone_on_cpu=False# 'Use CPUs to deploy clones.')\n",
    "\n",
    "\n",
    "num_replicas=1# 'Number of worker replicas.')\n",
    "\n",
    "\n",
    "startup_delay_steps=15#                     'Number of training steps between replicas startup.')\n",
    "\n",
    "\n",
    "num_ps_tasks=0#                     'The number of parameter servers. If the value is 0# then '                     'the parameters are handled locally by the worker.')\n",
    "\n",
    "\n",
    "master=''   #'='BNS name of the tensorflow server')\n",
    "\n",
    "\n",
    "task=0# 'The task ID.')\n",
    "\n",
    "\n",
    "# Settings for logging.\n",
    "\n",
    "train_logdir=None#                    'Where the checkpoint and logs are stored.')\n",
    "\n",
    "\n",
    "log_steps=10 # Display logging information at every log_steps.')\n",
    "\n",
    "\n",
    "save_interval_secs=1200# 'How often# in seconds# we save the model to disk.')\n",
    "\n",
    "\n",
    "save_summaries_secs=600 # 'How often# in seconds# we compute the summaries.')\n",
    "\n",
    "save_summaries_images=False#                     'Save sample inputs# labels# and semantic predictions as '                     'images to summary.')\n",
    "\n",
    "# Settings for training strategy.\n",
    "\n",
    "learning_policy='poly'#                  'Learning rate policy for training.')\n",
    "\n",
    "# Use 0.007 when training on PASCAL augmented training set# train_aug. When\n",
    "# fine-tuning on PASCAL trainval set# use learning rate=0.0001.\n",
    "base_learning_rate=.0001#                   'The base learning rate for model training.')\n",
    "\n",
    "learning_rate_decay_factor=0.1#                   'The rate to decay the base learning rate.')\n",
    "\n",
    "\n",
    "learning_rate_decay_step=2000#                     'Decay the base learning rate at a fixed step.')\n",
    "\n",
    "learning_power=0.9#                   'The power value used in the poly learning policy.')\n",
    "\n",
    "training_number_of_steps=30000#                     'The number of steps used for training')\n",
    "\n",
    "momentum=0.9# 'The momentum value to use')\n",
    "\n",
    "# When fine_tune_batch_norm=True# use at least batch size larger than 12\n",
    "# (batch size more than 16 is better). Otherwise# one could use smaller batch\n",
    "# size and set fine_tune_batch_norm=False.\n",
    "train_batch_size=8#                     'The number of images in each batch during training.')\n",
    "\n",
    "# For weight_decay# use 0.00004 for MobileNet-V2 or Xcpetion model variants.\n",
    "# Use 0.0001 for ResNet model variants.\n",
    "weight_decay=0.00004#                   'The value of the weight decay for training.')\n",
    "\n",
    "\n",
    "train_crop_size=[513,513]           # 'Image crop size [height# width] during training.')\n",
    "                 \n",
    "\n",
    "last_layer_gradient_multiplier=1.0#                   'The gradient multiplier for last layers# which is used to '                   'boost the gradient of last layers if the value > 1.')\n",
    "\n",
    "upsample_logits=True # 'Upsample logits during training.')\n",
    "# Settings for fine-tuning the network.\n",
    "\n",
    "tf_initial_checkpoint=None#                    'The initial checkpoint in tensorflow format.')\n",
    "\n",
    "# Set to False if one does not want to re-use the trained classifier weights.\n",
    "initialize_last_layer=True#                     'Initialize the last layer.')\n",
    "\n",
    "last_layers_contain_logits_only=False#                     'Only consider logits as last layers or not.')\n",
    "\n",
    "\n",
    "slow_start_step=0#                     'Training model with small learning rate for few steps.')\n",
    "\n",
    "slow_start_learning_rate=1e-4#                   'Learning rate employed during slow start.')\n",
    "\n",
    "# Set to True if one wants to fine-tune the batch norm parameters in DeepLabv3.\n",
    "# Set to False and use small batch size to save GPU memory.\n",
    "fine_tune_batch_norm=True#                     'Fine tune the batch norm parameters or not.')\n",
    "\n",
    "min_scale_factor=0.5#                   'Mininum scale factor for data augmentation.')\n",
    "\n",
    "max_scale_factor=2.#                   'Maximum scale factor for data augmentation.')\n",
    "\n",
    "scale_factor_step_size=0.25#                   'Scale factor step size for data augmentation.')\n",
    "\n",
    "# For `xception_65`# use atrous_rates = [12# 24# 36] if output_stride = 8# or\n",
    "# rates = [6# 12# 18] if output_stride = 16. For `mobilenet_v2`# use None. Note\n",
    "# one could use different atrous_rates/output_stride during training/evaluation.\n",
    "atrous_rates=None#                           'Atrous rates for atrous spatial pyramid pooling.')\n",
    "\n",
    "output_stride=16#                     'The ratio of input to output spatial resolution.')\n",
    "                 \n",
    "\n",
    "# Dataset settings.\n",
    "dataset_name='pascal_voc_seg'#                    'Name of the segmentation dataset.')\n",
    "                 \n",
    "\n",
    "train_split='train'#                    'Which split of the dataset to be used for training')\n",
    "                 \n",
    "\n",
    "dataset_dir=None# 'Where the dataset reside.\n",
    "                 \n",
    "#--train utils\n",
    "_ITEMS_TO_DESCRIPTIONS = {\n",
    "    'image': 'A color image of varying height and width.',\n",
    "    'labels_class': ('A semantic segmentation label whose size matches image.'\n",
    "                     'Its values range from 0 (background) to num_classes.'),\n",
    "}\n",
    "datasetDescriptor=collections.namedtuple(\n",
    "    'DatasetDescriptor',\n",
    "    [\n",
    "        'splits_to_size',\n",
    "        'name_classes', # 分类,包含背景类.例如pascal是20分类+1个背景\n",
    "        'ignore_label'\n",
    "    ]\n",
    ")\n",
    "\n",
    "_PASCAL_VOC=datasetDescriptor(\n",
    "    splits_to_size={\n",
    "        'train':2975,\n",
    "        'val':500,\n",
    "    },\n",
    "    num_classes=19,\n",
    "    ignore_label=255,\n",
    ")\n",
    "\n",
    "tfexample_decoder = slim.tfexample_decoder\n",
    "dataset = slim.dataset\n",
    "dataset_data_provider = slim.dataset_data_provider                 \n",
    "def get_dataset(dataset_name,split_name,dataset_dir):\n",
    "    \"\"\"获得slim dataset实例\n",
    "    \"\"\"\n",
    "    splite_size=_PASCAL_VOC.splits_to_size\n",
    "    name_classes=_PASCAL_VOC.name_classes\n",
    "    ignore_label=_PASCAL_VOC.ignore_label\n",
    "    \n",
    "    # file pattern\n",
    "    file_pattern=os.path.join(dataset_dir,'%s-*'%split_name)\n",
    "    \n",
    "    # TF 解码协议\n",
    "    keys_to_features={\n",
    "        'image/encoded':tf.FixedLenFeature(\n",
    "            (),tf.string,default_value=''),\n",
    "        'image/filename':tf.FixedLenFeature((),tf.string,default_value=''),\n",
    "        'image/format':tf.FixedLenFeature((),tf.string,default_value='jpeg'),\n",
    "        'image/height':tf.FixedLenFeature((),tf.int64,default_value=0),\n",
    "        'image/width':tf.FixedLenFeature((),tf.int64,default_value=0),\n",
    "        'image/height':tf.FixedLenFeature((),tf.int64,default_value=0),\n",
    "        'image/segmentation/class/encoded':tf.FixedLenFeature((),tf.string,default_value=''),\n",
    "        'image/segmentation/class/format':tf.FixedLenFeature((),tf.string,default_value='png'),\n",
    "    }\n",
    "    items_to_handlers={\n",
    "        'image':tfexample_decoder.Image(\n",
    "            image_key='image/encoded',\n",
    "            format_key='image/format',\n",
    "            channels=3),\n",
    "        'image_name':tfexample_decoder.Tensor('image/filename')\n",
    "        'height':tfexample_decoder.Tensor('image/height')\n",
    "        'width':tfexample_decoder.Tensor('image/width')\n",
    "        'labels_class':tfexample_decoder.Image(\n",
    "            image_key='image/segmentation/class/encoded',\n",
    "            format_key='image/segmentation/class/format',\n",
    "            channels=1),\n",
    "    }\n",
    "    decoder=tfexample_decoder.TFExampleDecoder(\n",
    "        keys_to_features,\n",
    "        items_to_handlers)\n",
    "    \n",
    "    return dataset.Dataset(\n",
    "        data_sources=file_pattern,\n",
    "        reader=rf.TFRecordReader,\n",
    "        decoder=decoder,\n",
    "        num_samples=splite_size[split_name],\n",
    "        items_to_descriptions=_ITEMS_TO_DESCRIPTIONS,\n",
    "        ignore_label=ignore_label,\n",
    "        num_classes=num_classes,\n",
    "        name=dataset_name,\n",
    "        multi_label=True)\n",
    "\n",
    "def resize_to_range(image,\n",
    "                    label=None,\n",
    "                    min_size=None,\n",
    "                    max_size=None,\n",
    "                    factor=None,\n",
    "                    align_corners=True,\n",
    "                    label_layout_is_chw=False,\n",
    "                    scope=None,\n",
    "                    method=tf.image.ResizeMethod.BILINEAR):\n",
    "    \"\"\"把图像做一个调整.\n",
    "       面试问题1: 如何对图像做调整,并手写调整方法.给出min max size,\n",
    "       返回: 整理好的image和label.\n",
    "    \"\"\"\n",
    "    with tf.name_scope(scope,'resize_to_range',[image]):\n",
    "        new_tensor_list=[]\n",
    "        \n",
    "    \n",
    "                 \n",
    "def input_get(dataset,\n",
    "        crop_size,\n",
    "        batch_size,\n",
    "        min_resize_value=None,\n",
    "        max_resize_value=None,\n",
    "        resize_factor=None,\n",
    "        min_scale_factor=1.,\n",
    "        max_scale_factor=1.,\n",
    "        scale_factor_step_size=0,\n",
    "        num_readers=1,\n",
    "        num_threads=1,\n",
    "        dataset_split=None,\n",
    "        is_training=True,\n",
    "        model_variant=None):\n",
    "    \"\"\"把dataset做一个分割split\n",
    "           这里分成了三步:\n",
    "           1. dataset_data_provider 函数会返回raw data.\n",
    "           2. 对raw data做预处理\n",
    "           3. 然后利用tf对预处理data做batching.\n",
    "       args:\n",
    "           dataset_split: 字符串,描述当前是train还是test\n",
    "    \"\"\"\n",
    "    data_provider=dataset_data_provider.DatasetDataProvider(\n",
    "        dataset,\n",
    "        num_readers=num_readers,\n",
    "        num_epochs=None if is_training else 1,\n",
    "        shuffle=is_training)\n",
    "    # get_data:\n",
    "    # 拿到 image,label,image_name,height,width\n",
    "    image,height,width=data_provider.get('image','height','width')\n",
    "    if 'image_name' in data_provider.list_items():\n",
    "        image_name,=data_provider.get('image_name')\n",
    "    else:\n",
    "        image_name=tf.constant('')\n",
    "    if dataset_split !='test':\n",
    "        label,=data_provider.get([labels_class])\n",
    "    else:\n",
    "        label=None\n",
    "    \n",
    "    # 检查label格式\n",
    "    if label is not None:\n",
    "        if label.shape.ndims==2:\n",
    "            #[height,width]类型的.\n",
    "            label=tf.expand_dims(label,2)\n",
    "        elif label.shape.ndims==3 and label.shape.dims[2]==1:\n",
    "            #[height,widht,1]类型的,第三个通道可以存在,但必须是1.要么就不存在好了.\n",
    "            pass\n",
    "        else:\n",
    "            raise(\"Label shoud be [h,w] or [h,w,1]\")\n",
    "    \n",
    "    # 对raw数据的pre process\n",
    "    process_image=tf.cast(image,tf.float32)\n",
    "    if label is not None:\n",
    "        label=tf.cast(label,tf.int32)\n",
    "    if min_resize_value is not None or max_resize_value is not None:\n",
    "        [processed_image,label]=(\n",
    "            resize_to_range(image=processed_image,\n",
    "                           label=label,\n",
    "                            min_size=min_resize_value,\n",
    "                            min_size=min_resize_value,\n",
    "                            max_size=max_resize_value,\n",
    "                            factor=resize_factor, # factor的倍数+1\n",
    "                            align_corners=True))\n",
    "        \n",
    "                 \n",
    "                 \n",
    "    \n",
    "                 \n",
    "def train():\n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "    config=model_deploy.DeploymentConfig(\n",
    "        num_clones=num_clones,\n",
    "        clone_on_cpu=clone_on_cpu,\n",
    "        replica_id=task,\n",
    "        num_replicas=num_replicas,\n",
    "        num_ps_tasks=num_ps_tasks)\n",
    "    \n",
    "    clone_batch_size=train_batch_size//config_num_clones\n",
    "    \n",
    "    dataset=get_dataset(\n",
    "        dataset_name,# 分割datasets的名字,是pascal_voc_seg还是什么.\n",
    "        train_split,# 字符串,'train_split'或者'train'\n",
    "        dataset_dir)# dataset路径\n",
    "    tf.gfile.MakeDirs(train_logdir)\n",
    "    tf.logging.info('Training on %s set',train_split)\n",
    "    \n",
    "    with tf.Graph().as_default() as graph:\n",
    "        with tf.device(config.inputs_device()):\n",
    "                samples=input_generator.get(\n",
    "                # 从数据集中拿到样本\n",
    "                dataset,\n",
    "                train_batch_size,\n",
    "                min_resize_value=min_resize_value,\n",
    "                max_resize_value=max_resize_value,\n",
    "                resize_factor=resize_factor,\n",
    "                min_scale_factor=min_scale_factor,\n",
    "                max_scale_factor=max_scale_factor,\n",
    "                scale_factor_step_size=scale_factor_step_size,\n",
    "                dataset_split=train_split,\n",
    "                is_training=True,\n",
    "                model_variant=model_variant)\n",
    "            # slim.prefetch_queue生成一个queue实例.\n",
    "            inputs_queue=prefetch_queue.prefetch_queue(\n",
    "                samples,capacity=128*config.num_clones)\n",
    "            \n",
    "        with tf.device(config.variables_device()):\n",
    "            global_step=tf.train.get_or_create_global_step() # 为当前图获得(有必要的话去创建)一个全局步数计数的tensor,一个graph只有一个这样的tensor.\n",
    "            model_args=(inputs_queue,{\n",
    "                common.OUTPUT_TYPE:dataset.num_classes\n",
    "            },dataset.ignore_label)\n",
    "            clones=model_deploy.create_clones(config,_build_deeplab,model_args)\n",
    "            \n",
    "            # 收集第一个clone的updates,可能有bn变量的update.\n",
    "            first_clone_scope=config.clone_scope(0)\n",
    "            update_ops=tf.get_collection(tf.Graphkeys.UPDATE_OPS,first_clone_scope)\n",
    "            \n",
    "        # 创建opt\n",
    "        with tf.device(config.optimizer_device()):\n",
    "            learing_rate=train_utils.get_module_learning_rate(\n",
    "                learing_policy,\n",
    "                base_learing_rate,\n",
    "                learing_rate_decay_step,\n",
    "                learing_rate_decay_factor,\n",
    "                training_number_of_steps,\n",
    "                learning_power,\n",
    "                slow_start_step,\n",
    "                slow_start_learing_rate)\n",
    "            optimizer=tf.train.MomentumOptimizer(learing_rate,momentum)\n",
    "            # add summary\n",
    "        startup_delay_steps=task*startup_delay_steps\n",
    "        # loss和opt\n",
    "        with tf.device(config.variables_devices()):\n",
    "            total_loss,grads_and_vars=model_deploy.optimize_clones(clones,optimizer)\n",
    "            total_loss=tf.check_numerics(total_loss,'total loss is inf or nan')\n",
    "            # summary total loss\n",
    "            # 拿到最后一层的vars\n",
    "            if last_layers_contain_logits_only:\n",
    "                last_layers=['logits']\n",
    "            else:\n",
    "                last_layers=[\n",
    "                    'logits',\n",
    "                    'image_pooling',\n",
    "                    'aspp',\n",
    "                    'concat_projection',\n",
    "                    'decoder',\n",
    "                ]\n",
    "            # 如果梯度需要按照不同的layer自定义存在.\n",
    "            grad_mul=train_utils.get_model_gradient_multipliers(\n",
    "                last_layers,last_layer_gradient_multiplier\n",
    "            )\n",
    "            \n",
    "            if grad_mul:\n",
    "                grads_and_vars=slim.learning.multiply_gradients(grads_and_vars,grad_mul)\n",
    "            \n",
    "            # 创建梯度更新的操作\n",
    "            grads_update=optimizer.apply_gradients(grads_and_vars,global_step=global_step)\n",
    "            update_ops.append(grads_update)\n",
    "            update_op=tf.group(*update_ops) # 把这些op组合在一起.\n",
    "            with tf.control_dependencies[update_op]:\n",
    "                train_tensor=tf.identity(total_loss,name=\"train_op\")\n",
    "            \n",
    "            session_config=tf.ConfigProto(allow_soft_placement=True,log_device_placement=False)\n",
    "            slim.learn.train(\n",
    "                train_tensor,\n",
    "                logdir=train_logdir,\n",
    "                log_every_n_steps=log_steps,\n",
    "                master=master,\n",
    "                number_of_steps=training_number_of_steps,\n",
    "                is_chief=(task == 0),\n",
    "                session_config=session_config,\n",
    "                startup_delay_steps=startup_delay_steps,\n",
    "                init_fn=train_utils.get_model_init_fn(\n",
    "                    train_logdir,\n",
    "                    tf_initial_checkpoint,\n",
    "                    initialize_last_layer,\n",
    "                    last_layers,\n",
    "                    ignore_missing_vars=True),\n",
    "                summary_op=summary_op,\n",
    "                save_summaries_secs=save_summaries_secs,\n",
    "                save_interval_secs=save_interval_secs\n",
    "            )\n",
    "\n",
    "            \n",
    "\n",
    "                 \n",
    "                  \n",
    "                  \n",
    "            \n",
    "    \n",
    "\n",
    "                \n",
    "    \n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### concat用法\n",
    "> dim是n,就是在n的维度上增加.把两个何在一起."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1:\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "t2:\n",
      "[[ 7  8  9]\n",
      " [10 11 12]]\n",
      "z0:\n",
      "[[ 1  2  3]\n",
      " [ 4  5  6]\n",
      " [ 7  8  9]\n",
      " [10 11 12]]\n",
      "z1:\n",
      "[[ 1  2  3  7  8  9]\n",
      " [ 4  5  6 10 11 12]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "t1 = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "t2 = tf.constant([[7, 8, 9], [10, 11, 12]])\n",
    "# 口诀: 0行加,1列加\n",
    "z0=tf.concat([t1, t2],0) #== > [[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]]\n",
    "z1=tf.concat([t1,t2],1)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(\"t1:\")\n",
    "    print(sess.run(t1))\n",
    "    print(\"t2:\")\n",
    "    print(sess.run(t2))\n",
    "    print(\"z0:\")\n",
    "    print(sess.run(z0))\n",
    "    print(\"z1:\")\n",
    "    print(sess.run(z1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "#### 几个需要解决的问题\n",
    "1. deeplab的评价标准?如何计算的评价标准.\n",
    "2. segNet的miou的计算公式.\n",
    "3. 自己测试集如何制作,以及对train,val,test的划分.\n",
    "4. softmax的公式?\n",
    "5. 样本不均衡怎么办?\n",
    "6. 怎样评估部署到手机端和pc端的精度?以及如何改进这些精度问题.\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ![image](https://img-blog.csdn.net/20180518234043625?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L29KaU1vRGVZZTEyMzQ1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](http://p0.ifengimg.com/pmop/2018/0326/34D889CEB77343C271F28FE97BBCF0CD5265946B_size25_w1080_h356.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.linspace(1,200,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.        ,   3.01010101,   5.02020202,   7.03030303,\n",
       "         9.04040404,  11.05050505,  13.06060606,  15.07070707,\n",
       "        17.08080808,  19.09090909,  21.1010101 ,  23.11111111,\n",
       "        25.12121212,  27.13131313,  29.14141414,  31.15151515,\n",
       "        33.16161616,  35.17171717,  37.18181818,  39.19191919,\n",
       "        41.2020202 ,  43.21212121,  45.22222222,  47.23232323,\n",
       "        49.24242424,  51.25252525,  53.26262626,  55.27272727,\n",
       "        57.28282828,  59.29292929,  61.3030303 ,  63.31313131,\n",
       "        65.32323232,  67.33333333,  69.34343434,  71.35353535,\n",
       "        73.36363636,  75.37373737,  77.38383838,  79.39393939,\n",
       "        81.4040404 ,  83.41414141,  85.42424242,  87.43434343,\n",
       "        89.44444444,  91.45454545,  93.46464646,  95.47474747,\n",
       "        97.48484848,  99.49494949, 101.50505051, 103.51515152,\n",
       "       105.52525253, 107.53535354, 109.54545455, 111.55555556,\n",
       "       113.56565657, 115.57575758, 117.58585859, 119.5959596 ,\n",
       "       121.60606061, 123.61616162, 125.62626263, 127.63636364,\n",
       "       129.64646465, 131.65656566, 133.66666667, 135.67676768,\n",
       "       137.68686869, 139.6969697 , 141.70707071, 143.71717172,\n",
       "       145.72727273, 147.73737374, 149.74747475, 151.75757576,\n",
       "       153.76767677, 155.77777778, 157.78787879, 159.7979798 ,\n",
       "       161.80808081, 163.81818182, 165.82828283, 167.83838384,\n",
       "       169.84848485, 171.85858586, 173.86868687, 175.87878788,\n",
       "       177.88888889, 179.8989899 , 181.90909091, 183.91919192,\n",
       "       185.92929293, 187.93939394, 189.94949495, 191.95959596,\n",
       "       193.96969697, 195.97979798, 197.98989899, 200.        ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.5\n"
     ]
    }
   ],
   "source": [
    "sess=tf.Session()\n",
    "y=tf.reduce_mean(x)\n",
    "print(sess.run(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 6 7 8]\n",
      "[[[1 2]\n",
      "  [3 4]]\n",
      "\n",
      " [[5 6]\n",
      "  [7 8]]]\n",
      "reduce\n",
      "[2 6]\n",
      "reduce axis=0\n",
      "[[3 4]\n",
      " [5 6]]\n",
      "reduce axis=1\n",
      "[[2 3]\n",
      " [6 7]]\n",
      "reduce axis=2\n",
      "[[1 3]\n",
      " [5 7]]\n"
     ]
    }
   ],
   "source": [
    "#x1=tf.reshape(x,(5,5,5))\n",
    "z= tf.constant([1, 2, 3, 4, 5, 6, 7,8])\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print(sess.run(z))\n",
    "z_r=tf.reshape(z,[2,2,2])\n",
    "print(sess.run(z_r))\n",
    "y_r=tf.reduce_mean(z_r,axis=[1,2])\n",
    "print(\"reduce\")\n",
    "print(sess.run(y_r))\n",
    "y0=tf.reduce_mean(z_r,axis=0)\n",
    "print(\"reduce axis=0\")\n",
    "print(sess.run(y0))\n",
    "\n",
    "y1=tf.reduce_mean(z_r,axis=1)\n",
    "print(\"reduce axis=1\")\n",
    "print(sess.run(y1))\n",
    "\n",
    "\n",
    "y2=tf.reduce_mean(z_r,axis=2)\n",
    "print(\"reduce axis=2\")\n",
    "print(sess.run(y2))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
