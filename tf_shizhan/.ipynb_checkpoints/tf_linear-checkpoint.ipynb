{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/miniconda3/envs/dl/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/miniconda3/envs/dl/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:118: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "0 [[-0.20146708  0.80983573]] [0.34215036]\n",
      "20 [[0.04614187 0.29653376]] [0.280538]\n",
      "40 [[0.09375869 0.21796922]] [0.29426846]\n",
      "60 [[0.09997188 0.20369442]] [0.29812226]\n",
      "80 [[0.10037021 0.20087546]] [0.29934502]\n",
      "100 [[0.10020063 0.20024227]] [0.29976404]\n",
      "120 [[0.10008495 0.2000761 ]] [0.29991364]\n",
      "140 [[0.10003322 0.20002592]] [0.29996818]\n",
      "160 [[0.10001261 0.20000923]] [0.29998824]\n",
      "180 [[0.1000047  0.20000333]] [0.29999566]\n",
      "200 [[0.10000175 0.20000121]] [0.29999837]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# 使用 NumPy 生成假数据(phony data), 总共 100 个点.\n",
    "x_data = np.float32(np.random.rand(2, 100)) # 随机输入\n",
    "y_data = np.dot([0.100, 0.200], x_data) + 0.300\n",
    "\n",
    "# 构造一个线性模型\n",
    "# \n",
    "b = tf.Variable(tf.zeros([1]))\n",
    "W = tf.Variable(tf.random_uniform([1, 2], -1.0, 1.0))\n",
    "y = tf.matmul(W, x_data) + b\n",
    "\n",
    "# 最小化方差\n",
    "loss = tf.reduce_mean(tf.square(y - y_data))\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# 初始化变量\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "# 启动图 (graph)\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# 拟合平面\n",
    "for step in range(0, 201):\n",
    "    sess.run(train)\n",
    "    if step % 20 == 0:\n",
    "        print (step, sess.run(W), sess.run(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "low,high -0.07808688094430304 0.07808688094430304\n",
      "epoch: 1\n",
      "cost: 43847947.827363588\n",
      "epoch: 2\n",
      "cost: 141891749.410981894\n",
      "epoch: 3\n",
      "cost: 122075647.066399902\n",
      "epoch: 4\n",
      "cost: 43747232.404854506\n",
      "epoch: 5\n",
      "cost: 82034766.224109083\n",
      "epoch: 6\n",
      "cost: 70820206.346818417\n",
      "epoch: 7\n",
      "cost: 1761853.141545454\n",
      "epoch: 8\n",
      "cost: 4702103.469727276\n",
      "epoch: 9\n",
      "cost: 112355374.495918125\n",
      "epoch: 10\n",
      "cost: 6457566111.813563347\n",
      "epoch: 11\n",
      "cost: 327439451.144654989\n",
      "epoch: 12\n",
      "cost: 229716998.686581761\n",
      "epoch: 13\n",
      "cost: 854376189.858836532\n",
      "epoch: 14\n",
      "cost: 342147684.185236275\n",
      "epoch: 15\n",
      "cost: 93247421.733163655\n",
      "epoch: 16\n",
      "cost: 4236017.828690909\n",
      "epoch: 17\n",
      "cost: 43815534.295272723\n",
      "epoch: 18\n",
      "cost: 129121318.544472635\n",
      "epoch: 19\n",
      "cost: 744879732.425400138\n",
      "epoch: 20\n",
      "cost: 308654911.872945309\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sklearn.preprocessing as prep\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "\n",
    "def xaver_init(fan_in, fan_out, constant=1):\n",
    "    # 创造一个权重均值为0方差为2/(nin+nout)。\n",
    "    # 深度学习的权重如果选的小，则信号在每层间的传递会弱。\n",
    "    # 如果权重取得过大，信号在传递中会被放大而发散，甚至失效。\n",
    "\n",
    "    low = -constant * np.sqrt(6.0 / (fan_in + fan_out))\n",
    "    high = constant * np.sqrt(6.0 / (fan_in + fan_out))\n",
    "    print(\"low,high\", low, high)\n",
    "    return tf.random_uniform((fan_in, fan_out), minval=low, maxval=high, dtype=tf.float32)\n",
    "\n",
    "# xaver_init(1,2,1)\n",
    "class AdditiveGaussianNoiseAutoEncoder(object):\n",
    "    def __init__(self, n_input, n_hidden, transfer_function=tf.nn.softplus  # 激活函数\n",
    "                 , optimizer=tf.train.AdamOptimizer(), scale=0.1):\n",
    "        self.n_input = n_input\n",
    "        self.n_hidden = n_hidden\n",
    "        self.transfer = transfer_function\n",
    "        self.scale = tf.placeholder(tf.float32)  # 预先占位\n",
    "        self.training_scale = scale\n",
    "        network_weights = self._initialize_weights()  # 这个是什么？\n",
    "        self.weights = network_weights\n",
    "\n",
    "        # 创建网络\n",
    "        self.x = tf.placeholder(tf.float32, [None, self.n_input])\n",
    "        #step 1 ： 输入加噪声。\n",
    "        noise_input_data = self.x + scale*tf.random_normal((n_input,))\n",
    "        #step 2: y = wx+b\n",
    "\n",
    "        self.n_hidden = self.transfer(tf.add(tf.matmul(noise_input_data, self.weights['w1']), self.weights['b1']))\n",
    "        self.reconstruction = tf.add( tf.matmul(self.n_hidden, self.weights['w2']), self.weights['b2'])\n",
    "\n",
    "        # 创建损失函数\n",
    "        # x2\n",
    "        self.cost = tf.reduce_sum(tf.pow(tf.subtract(self.reconstruction,self.x),2))\n",
    "        self.optimizer = optimizer.minimize(self.cost)\n",
    "        init = tf.global_variables_initializer()\n",
    "        self.sess = tf.Session()\n",
    "        self.sess.run(init)\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        all_weights = dict()\n",
    "        all_weights['w1'] = tf.Variable(xaver_init(self.n_input,self.n_hidden))\n",
    "        all_weights['b1'] = tf.Variable(tf.zeros([self.n_hidden]),tf.float32)\n",
    "        all_weights['w2'] = tf.Variable(tf.zeros([self.n_hidden,self.n_input],tf.float32))\n",
    "        all_weights['b2'] = tf.Variable(tf.zeros([self.n_input],tf.float32))\n",
    "        return all_weights\n",
    "\n",
    "    def partial_fit(self,X):\n",
    "        cost, opt = self.sess.run((self.cost,self.optimizer),feed_dict={self.x:X,self.scale:self.training_scale})\n",
    "        return cost\n",
    "\n",
    "    def calc_total_cost(self,X):\n",
    "        return self.sess.run(self.cost, feed_dict={self.x:X, self.scale:self.training_scale})\n",
    "\n",
    "    def tranform(self,X):\n",
    "        return self.sess.run(self.n_hidden, feed_dict={self.x: X, self.scale: self.training_scale})\n",
    "\n",
    "    def generate(self,hidden=None):\n",
    "        if hidden is None:\n",
    "            hidden = np.random.normal(size=self.weights[\"b1\"])\n",
    "        return self.sess.run(self.reconstruction,feed_dict={self.n_hidden:hidden})\n",
    "    def reconstrct(self,X):\n",
    "        return self.sess.run(self.reconstruction, feed_dict={self.x: X, self.scale: self.training_scale})\n",
    "\n",
    "    def getWeights(self):\n",
    "        return self.sess.run(self.weights['w1'])\n",
    "\n",
    "    def getBiases(self):\n",
    "        return self.sess.run(self.weights['b1'])\n",
    "\n",
    "def standard_scale(X_train, X_test):\n",
    "    preprocessor = prep.StandardScaler().fit(X=X_train) #StandardScaler()要加上括号的\n",
    "    X_train = preprocessor.transform(X_train)\n",
    "    X_test  = preprocessor.transform(X_test)\n",
    "    return X_train, X_test\n",
    "\n",
    "def get_random_block_from_data(data,batch_size):\n",
    "    start_index = np.random.randint(0,len(data)-batch_size)\n",
    "    return data[start_index:(start_index+batch_size)]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "    X_train, X_test = standard_scale(mnist.train.images, mnist.test.images)\n",
    "    n_samples = int(mnist.train.num_examples)\n",
    "    training_epochs = 20\n",
    "    batch_size = 128\n",
    "    display_step = 1\n",
    "    autoEncoder = AdditiveGaussianNoiseAutoEncoder(n_input=784, n_hidden=200,\n",
    "                                     transfer_function=tf.nn.softplus,\n",
    "                                     optimizer=tf.train.AdamOptimizer(learning_rate=0.01),\n",
    "                                     scale=0.01)\n",
    "\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    "        total_batch = int(n_samples/batch_size)\n",
    "        for i in range(total_batch):\n",
    "            batch_xs = get_random_block_from_data(X_train,batch_size)\n",
    "            cost = autoEncoder.partial_fit(batch_xs)\n",
    "            avg_cost += cost/n_samples*batch_size # 不是很懂\n",
    "\n",
    "        if epoch % display_step == 0:\n",
    "            print(\"epoch:\",epoch+1)\n",
    "            print(\"cost:\", \"{:.9f}\".format(avg_cost))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w shape (55000, 200)\n"
     ]
    }
   ],
   "source": [
    "w = autoEncoder.tranform(X_train)\n",
    "print(\"w shape\",w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"w[0]\",w[0])\n",
    "w_r = w[0].reshape((40,5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
